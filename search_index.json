[["index.html", "PO12Q: Seminar Companion Preface", " PO12Q: Seminar Companion Dr Flo Reiche Department of Politics and International Studies University of Warwick Last Updated 09 December, 2024 Preface This is the online companion to the seminars on PO12Q. This replaces the physical worksheets which we work through in seminars for two reasons: it is environmentally friendlier you can copy / paste code directly from the code chunks in this online companion, whereas doing so from a pdf (on Moodle) tends to lead to problems with character encoding. I hope you find this useful! "],["companion-features.html", "Companion Features", " Companion Features You will find embedded in the text four different types of boxes which serve different purposes: This box appears whenever I want you to stop at a particular point in the worksheet and to flag up to me or Luis that you are done. Some explanations that will hopefully make your work with this webpage or learning the material itself easier. We will start working with matrices in Week 3, and I have recorded some videos to ease you into working with them. A brief question which tests your understanding of the previous material. This appears when you need to be careful with your coding in R to avoid problems. "],["methods-methods-methods.html", "Methods, Methods, Methods Data Prep Video and RScript", " Methods, Methods, Methods Whenever I introduce you to a new method on this module, you will find this section here on the companion. It will contain an RScript for some preliminary data preparation. This is not an actual part of introducing the method, but you are certainly encouraged to read it and to try and understand it. These sections will work with the American National Election Studies (ANES), and to be more precise with the pilot survey conducted before the 2020 presidential election. You can download the required data set here. The original is available here. Data Prep Place the ANES data in a folder which you will be using as a working directory for this session. Open the RScript and change the setwd() command at the beginning to your own working directory. Then run the RScript and you will be ready to proceed to the video. Video and RScript You can find the video introducing you to creating cross-tabulations in R by way of a worked example below. We are going to investigate whether sex influences support for Trump. You can also download the RScriptI am typing up in the video. I would encourage you to type it yourself, though, as then code tends to better sink into the depths of your brain ;) Cross Tabulations in R "],["worksheet-week-1.html", "Worksheet Week 1 Self-Assessment Questions1 Calculations by Hand Cross-Tabulations in R Solutions", " Worksheet Week 1 Self-Assessment Questions1 What do cross-tabulations do? Can we use continuous variables for cross-tabulations? What are the strengths and weaknesses of cross-tabulations? Why do we calculate the \\(\\chi^2\\)-value as \\(\\chi^{2} = \\Sigma \\frac{(f_{o}-f_{e})^{2}}{f_{e}}\\) ? How does the \\(\\chi^2\\) distribution differ from the t- and normal distribution? Please stop here and don’t go beyond this point until we have compared notes on your answers. Calculations by Hand I have given you an example of a cross-tabulation in the lecture. Consider the following Table: Calculate the Expected Values and fill in the following table: Calculate the \\(\\chi^{2}\\)-value How many degrees of freedom does this table have? Why? Using the \\(\\chi^2\\) Table, what is the p-value? Are mode of transport and year of study independent in the population? Cross-Tabulations in R If you have joined PO12Q without suffering through PO11Q, then please work through these two worksheets before proceeding with the present material: PO11Q Worsheet, Week 5 PO11Q Worsheet, Week 7 Data Set We are working with the World Development Indicators this week. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). Download the data WDI_PO12Q.csv and place it in a new working directory for this week The variables we will be working with today are as follows: Table 1: WDI Codebook variable label Country Name Country Name Country Code Country Code year year gdppc GDP per capita (constant 2010 US$) gdpgrowth Absolute growth of per capita GDP to previous year (constant 2010 US Dollars) enrl_gross School enrollment, primary (% gross) enrl_net School enrollment, primary (% net) agri Employment in agriculture (% of total employment) (modeled ILO estimate) slums Population living in slums (% of urban population) telephone Fixed telephone subscriptions (per 100 people) internet Individuals using the Internet (% of population) tax Tax revenue (% of GDP) electricity Access to electricity (% of population) mobile Mobile cellular subscriptions (per 100 people) service Services, value added (% of GDP) oil Oil rents (% of GDP) natural Total natural resources rents (% of GDP) literacy Literacy rate, adult total (% of people ages 15 and above) prim_compl Primary completion rate, total (% of relevant age group) infant Mortality rate, infant (per 1,000 live births) hosp Hospital beds (per 1,000 people) tub Incidence of tuberculosis (per 100,000 people) health_ex Current health expenditure (% of GDP) ineq Income share held by lowest 10% unemploy Unemployment, total (% of total labor force) (modeled ILO estimate) lifeexp Life expectancy at birth, total (years) urban Urban population (% of total population) polity5 Combined Polity V score Loading the Data Code setwd(&quot;~/PO12Q/Seminars/PO12Q_Seminar_Week 1&quot;) wdi &lt;- read.csv(&quot;WDI_PO12Q.csv&quot;) You can copy the code from this page by hovering over the code chunk and clicking the icon in the top-right hand corner. You can then paste it into your RScript. Guided Example We are now going to use the WDI, and produce a crosstab of Life expectancy at birth, total (years) by GDP per capita (constant 2010 US$), using the variables lifeexp and gdppc We first need to recode both variables into factor variables, as these are continuous. First up is lifeexp Recoding: as a refresher from PO11Q, we are specifying the new data frame as the old one, then we add a pipe, and call the function mutate. Therein, we create a new variable called lifecat, which will be an ordered factor, cutting the variable life at the stated intervals, and labeling these levels accordingly. Code library(tidyverse) wdi &lt;- wdi %&gt;% mutate(lifecat= ordered( cut(lifeexp, breaks=c(0,77,84), labels=c(&quot;low&quot;,&quot;high&quot;)))) Make a habit of adding a note underneath each code chunk in your RScript (with a ‘#’) in which you translate the code into plain English. Next up is gdppc which we are recoding into a factor variable with three levels: Code wdi &lt;- wdi %&gt;% mutate(gdpcat= ordered( cut(gdppc, breaks=c(0,3861.5,25260, 150000), labels=c(&quot;low&quot;,&quot;medium&quot;, &quot;high&quot;)))) Let us now see whether the level of GDP has an influence on life expectancy State the null and the alternative hypothesis (directional) Run the cross-tabulation, by calling: Code wdi_table &lt;- with(wdi, table(gdpcat, lifecat)) wdi_table lifecat gdpcat low high low 69 0 medium 54 16 high 3 27 Now perform a chi-squared test, using the command2 Code Xsq &lt;- chisq.test(wdi_table, correct=FALSE) Xsq Pearson&#39;s Chi-squared test data: wdi_table X-squared = 89.702, df = 2, p-value &lt; 2.2e-16 As on PO11Q, you can find all R functions on the POQ Flashcard Section of my webpage. Are the results statistically significant? At what level? What do these results mean for our hypotheses? Produce the table of expected frequencies, using the command Code round(Xsq$expected, 2) lifecat gdpcat low high low 51.44 17.56 medium 52.19 17.81 high 22.37 7.63 You can compare that to the observed ones: Code round(Xsq$observed, 2) lifecat gdpcat low high low 69 0 medium 54 16 high 3 27 You can see that this is identical to producing the cross-tabulation in the first place: Code wdi_table lifecat gdpcat low high low 69 0 medium 54 16 high 3 27 In plain English: What have we found out? Exercises Let us find out whether the completion of primary school influences unemployment rates. State the null and directional alternative hypothesis for this test. Create a new variable primary_fac using the prim_compl variable. Cut it into three categories “low”, “medium”, and “high”, cutting prim_compl at its first quartile, and its mean. Apply the same procedure to unemploy, creating a new variable called unemp_fac. Create a cross-tabulation assessing the dependence of unemployment on primary completion rate. unemp_fac. Test whether the dependence is statistically significant. unemp_fac. Repeat steps 1a) to 1e) for two variables of your own choice. Solutions You can find the Solutions in the Downloads Section. Some of the content of this worksheet is taken from Reiche (forthcoming).↩︎ I am using the correct=FALSE option here to reproduce the \\(\\chi^{2}\\)-value you would get if you calculated this by hand. Technically, \\(\\chi^{2}\\) is only an approximation of the hypergeometric distribution which would deliver an exact test. You can get the precise value by applying Yates’ continuity correction with correct=TRUE.↩︎ "],["worksheet-week-2.html", "Worksheet Week 2 Self-Assessment Questions3 Two-Sample Tests in R Solutions", " Worksheet Week 2 Self-Assessment Questions3 Give an example for a two-sample test for a mean. Give an example for a two-sample test for a proportion. Why do we calculate the t-score as \\(t =\\frac{\\text{Estimate of parameter - null hypothesis value of parameter}}{\\text{Standard error of estimate}}\\) ? What is the difference between a t-score and a z-score? What are the strengths and weaknesses of two-sample tests? Please stop here and don’t go beyond this point until we have compared notes on your answers. Two-Sample Tests in R Data Preparation We are working with the World Development Indicators again. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). To save you rooting in your files, here is the codebook (you are welcome): Table 2: WDI Codebook variable label Country Name Country Name Country Code Country Code year year gdppc GDP per capita (constant 2010 US$) gdpgrowth Absolute growth of per capita GDP to previous year (constant 2010 US Dollars) enrl_gross School enrollment, primary (% gross) enrl_net School enrollment, primary (% net) agri Employment in agriculture (% of total employment) (modeled ILO estimate) slums Population living in slums (% of urban population) telephone Fixed telephone subscriptions (per 100 people) internet Individuals using the Internet (% of population) tax Tax revenue (% of GDP) electricity Access to electricity (% of population) mobile Mobile cellular subscriptions (per 100 people) service Services, value added (% of GDP) oil Oil rents (% of GDP) natural Total natural resources rents (% of GDP) literacy Literacy rate, adult total (% of people ages 15 and above) prim_compl Primary completion rate, total (% of relevant age group) infant Mortality rate, infant (per 1,000 live births) hosp Hospital beds (per 1,000 people) tub Incidence of tuberculosis (per 100,000 people) health_ex Current health expenditure (% of GDP) ineq Income share held by lowest 10% unemploy Unemployment, total (% of total labor force) (modeled ILO estimate) lifeexp Life expectancy at birth, total (years) urban Urban population (% of total population) polity5 Combined Polity V score Load the data set The Polity V Score (variable polity5) codes regimes from -10 (indicating perfect autocracy) to +10 (indicating perfect democracy). With the tidyvserse, create a new variable called democracy which codes all countries with a Polity V score lower than +1 as dictatorships, and all countries with a Polity V score from +1 to +10 as democracies. Apply the same procedure to gdp, cutting it at its median into two levels, Developing and Developed, creating a new variable called gdpcat. Last up is the variable gdpgrowth. Create a new variable called growth which divides countries into “slow-growing” and “fast-growing” countries, using the mean as the cut-off point. Guided Example – Two-Sample Test for a Proportion Let us find out whether a higher proportion of developed countries is democratic than developing countries. State the null hypothesis and the directional alternative hypothesis for this research question. In order to test this hypothesis, we need to first create a cross-tabulation: Code table(wdi$gdpcat, wdi$politybin) Dictatorship Democracy Developing 21 36 Developed 19 71 We now take the number of observations which are classed as democracies per development status. We also calculate the row totals, as this gives us the total number of developing and developed countries, respectively. Then we are ready to use the prop.test() command, by first specifying the number of countries which are democracies, then the total number of developing and developed countries, then advising R that a correction for small sample sizes is not necessary in our case. Our hypothesis is directional, because we expect a higher proportion of developed countries to be democratic than developing countries. The status Developing is the lower category, and we thus expect this proportion to be smaller, or “less”. We add this to the test function as option alternative = \"less\". Code prop.test(c(36,71),c(57,90), correct=F, alternative = &quot;less&quot;) 2-sample test for equality of proportions without continuity correction data: c(36, 71) out of c(57, 90) X-squared = 4.3602, df = 1, p-value = 0.01839 alternative hypothesis: less 95 percent confidence interval: -1.00000000 -0.03061662 sample estimates: prop 1 prop 2 0.6315789 0.7888889 Which proportion of developing and developed countries are democratic? Do we verify or falsify our hypothesis at a 95% confidence level? How would the R code change, if we investigated whether a higher proportion of developing countries is autocratic than developed countries? Exercise – Two-Sample Test for a Proportion Is a higher proportion of fast-growing countries democratic than slow-growing countries? Use a 95% confidence level. Guided Example – Two-Sample Test for a Mean Now we are interested whether people live longer in developed countries than in developing countries? For this, we use the variable life Once again, state the Null- and the Alternative Hypothesis The t-test assumes an equal variance in both samples, and so we need to test whether this is the case. We will do this with the so-called Levene Test, where: H\\(_{0}\\): The variance among the groups is equal. H\\(_{\\text{A}}\\): The variance among the groups is not equal. This is essentially another two-sample test in which we ascertain whether the difference between the variances of the two groups is different from zero (H\\(_{0}\\)) For the Levene test you need the car package, where “car” stands for “Companion to Applied Regression”: Code install.packages(&quot;car&quot;) Now we call the package and perform the test: Code library(car) leveneTest(wdi$lifeexp ~ wdi$gdpcat) Levene&#39;s Test for Homogeneity of Variance (center = median) Df F value Pr(&gt;F) group 1 3.7671 0.05395 . 167 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The result is insignificant, and we therefore accept the null hypothesis. This means that the variance in the two samples is equal. Now we can perform the t-test. We once again specify alternative=\"less\" as an option, due to the same reasoning as before. Code t.test(lifeexp ~ gdpcat, data=wdi, var.equal = TRUE, alternative=&quot;less&quot;) Two Sample t-test data: lifeexp by gdpcat t = -12.01, df = 167, p-value &lt; 2.2e-16 alternative hypothesis: true difference in means between group Developing and group Developed is less than 0 95 percent confidence interval: -Inf -9.53028 sample estimates: mean in group Developing mean in group Developed 64.65938 75.71177 Can we conclude at a 95% confidence level, that people live longer in developed countries than in developing countries? What is the precise p-value for the hypothesis that the true difference in means between group Developing and group Developed is greater than 0? Exercise – Two-Sample Test for a Mean Do people live longer under democracies than under dictatorahips (use the politybin variable)? Use a 95% confidence level. Solutions You can find the Solutions in the Downloads Section. Some of the content of this worksheet is taken from Reiche (forthcoming).↩︎ "],["introduction-to-matrices.html", "Introduction to Matrices What is a Matrix?4 Matrix Notation Calculating with Matrices Special Matrices", " Introduction to Matrices What is a Matrix?4 The word “matrix” generally conjures up levels of horror in students which even Stephen King would be struggling to match5. And I have to admit that I have not always been best friends with them myself, either. But they are useful, and in their ability to convey a large amount of information in a structured and logical way, they are even beautiful. Because at the end of the day, a matrix is nothing more than a list. In the lecture I introduced you to the concept of the Population Regression Function (PRF) which can be written as: \\[\\begin{equation} y_{i} = \\beta_{0} + \\beta_{1} x_{i} + \\epsilon_{i} \\end{equation}\\] If we wanted to write out this equation for every observation in our data set, it would look something like this: \\[\\begin{align*} y_{1} &amp;= \\beta_{0} + \\beta_{1} x_{1} + \\epsilon_{1} \\\\ y_{2} &amp;= \\beta_{0} + \\beta_{1} x_{2} + \\epsilon_{2} \\\\ &amp;\\vdots \\\\ y_{n} &amp;= \\beta_{0} + \\beta_{1} x_{n} + \\epsilon_{n} \\end{align*}\\] This is incredibly wasteful, as it unnecessarily repeats notation. What we could do instead is to create a list which has as many columns as there are unique elements in these equations (since they all have the same structure), and only note the numeric values which actually change. And there you have a matrix: Whilst this is what we will be using matrices for next week, let us leave regression aside for now, and focus on working with matrices more generally. We will now be using these two sample matrices: \\[\\begin{equation*} A = \\begin{bmatrix} 1 &amp; 7 &amp; 3\\\\ 9 &amp; 5 &amp; 4\\\\ \\end{bmatrix} \\hspace{0.75cm} B = \\begin{bmatrix} 6 &amp; 3 &amp; 8 &amp; 2 \\\\ 3 &amp; 2 &amp; 1 &amp; 4 \\\\ 1 &amp; 5 &amp; 3 &amp; 9 \\\\ \\end{bmatrix} \\end{equation*}\\] Matrix Notation We can refer to individual elements of a matrix by stating the name of the matrix, and then in the index first the row, followed by the column (you might recognise this logic from R – this is because it is the same). With respect to matrix A, for example, the value in the first row and first column (1) would be referred to as A\\(_{11}=1\\) The number in the first row, but second column would be referred to as A\\(_{12}=7\\) What is the value of B\\(_{23}\\)? Calculating with Matrices We will only need to multiply and divide matrices on this module, so let’s cover these operations now. Multiplying Matrices To show you how this is done, I will multiply matrix A with matrix B and record the results in a new matrix called C. \\[\\begin{equation*} A \\times B = C = \\begin{bmatrix} 1 &amp; 7 &amp; 3\\\\ 9 &amp; 5 &amp; 4\\\\ \\end{bmatrix} \\times \\begin{bmatrix} 6 &amp; 3 &amp; 8 &amp; 2 \\\\ 3 &amp; 2 &amp; 1 &amp; 4 \\\\ 1 &amp; 5 &amp; 3 &amp; 9 \\\\ \\end{bmatrix} = \\begin{bmatrix} 30 &amp; 32 &amp; 24 &amp; 51\\\\ 73 &amp; 57 &amp; 89 &amp; 74\\\\ \\end{bmatrix} \\end{equation*}\\] In order to calculate a new element \\(C_{i,j}\\), we multiply the elements of the \\(i^{th}\\) row of A with the elements of the \\(j^{th}\\) column of B. We then add together these so-called inner products in order to arrive at \\(C_{i,j}\\). Let me give you some examples in which I have set the values from matrix A in bold to make the process more transparent. \\(C_{11}=\\textbf{1}\\times6+\\textbf{7}\\times3+\\textbf{3}\\times1=30\\) \\(C_{12}=\\textbf{1}\\times3+\\textbf{7}\\times2+\\textbf{3}\\times5=32\\) \\(C_{21}=\\textbf{9}\\times6+\\textbf{5}\\times3+\\textbf{4}\\times1=73\\) I have prepared a short video taking you through this process step by step. I would encourage you to watch it now. If you can’t get enough of my delightful German accent, then I have some videos for you in which I go through the respective operation with matrices on screen. Here is the first: Multiplying Matrices Assume we are multiplying a 4x3 matrix with a 3x4 matrix with one another. How many rows and columns does the resulting matrix have? Dividing Matrices In order to be able to divide by an entire matrix, we take its inverse, and then multiply with the inverse6. We do the same in the non-matrix world. For example, if we wanted to divide 6 by 3, this is the same as multiplying 6 with \\(\\frac{1}{3}\\), the inverse of 3. Sadly, inverting a matrix is not quite as straightforward as this. In fact, it is one of the most challenging operations you can do with a matrix. Luckily, the inversion of a 2 by 2 matrix (which is what we will be using) is still possible without a degree in algebra. The inverse \\(D^{-1}\\) of a 2 by 2 matrix \\(D\\) is defined as \\[\\begin{equation*} D^{-1} = \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\\\ \\end{bmatrix}^{-1} = \\frac{1}{ad-bc} \\begin{bmatrix} d &amp; -b \\\\ -c &amp; a \\\\ \\end{bmatrix}^{-1} \\end{equation*}\\] Thus, to arrive at the inverse of a 2 by 2 matrix, we first have to form the fraction in front of it. This takes as its denominator the difference between the products of the diagonal elements. We also refer to the denominator as the determinant of the matrix. In a second step – now in the matrix itself – we swap a and d, and set a minus sign in front of b and c. Dividing Matrices Special Matrices There are two types of matrices we will be using which hold special, useful properties. This is the transpose of a matrix, and the so-called identity matrix. Transposing Matrices Another important operation is transposing a matrix, which turns rows into columns and columns into rows. We denote a transposed matrix with an apostrophe. Transposing matrix \\(A\\) into matrix \\(A^\\prime\\) gives us: \\[\\begin{equation*} A = \\begin{bmatrix} 1 &amp; 7 &amp; 3\\\\ 9 &amp; 5 &amp; 4\\\\ \\end{bmatrix} \\hspace{0.75cm} A^\\prime = \\begin{bmatrix} 1 &amp; 9 \\\\ 7 &amp; 5 \\\\ 3 &amp; 4 \\\\ \\end{bmatrix} \\end{equation*}\\] Transposing Matrices We have the following matrix: \\[\\begin{equation*} X = \\begin{bmatrix} 2 &amp; 4 \\\\ 3 &amp; 6 \\\\ \\end{bmatrix} \\end{equation*}\\] Calculate \\(X^{\\prime}X\\). The Identity Matrix There is only one last thing left to show you before we can embark on using matrices for deriving and estimating our regression coefficients. And that is the so-called identity matrix \\(I\\). This matrix is always square, has the value 1 on all diagonal elements, and zeros otherwise. If a matrix is multiplied with \\(I\\), we receive the original matrix. For example let \\[\\begin{equation*} I = \\begin{bmatrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1\\\\ \\end{bmatrix} \\end{equation*}\\] If we multiply I with matrix B we receive \\[\\begin{equation*} I \\times B = \\begin{bmatrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1\\\\ \\end{bmatrix} \\times \\begin{bmatrix} 6 &amp; 3 &amp; 8 &amp; 2 \\\\ 3 &amp; 2 &amp; 1 &amp; 4 \\\\ 1 &amp; 5 &amp; 3 &amp; 9 \\\\ \\end{bmatrix} = \\begin{bmatrix} 6 &amp; 3 &amp; 8 &amp; 2 \\\\ 3 &amp; 2 &amp; 1 &amp; 4 \\\\ 1 &amp; 5 &amp; 3 &amp; 9 \\\\ \\end{bmatrix} \\end{equation*}\\] This feature will be important in the derivation of estimators next week, where we will make use of the fact that a matrix multiplied with its inverse results in an identity matrix. For example \\(A \\times A^{-1} = I\\). Identity Matrix This material is taken from Reiche (forthcoming).↩︎ He is by far my favourite author. If you haven’t, already, read IT.↩︎ This draws on https://www.mathsisfun.com/algebra/matrix-inverse.html↩︎ "],["worksheet-week-3.html", "Worksheet Week 3 Self-Assessment Questions7 Regression – Theory Calculations with Matrices Homework", " Worksheet Week 3 Self-Assessment Questions7 Explain the difference between \\(\\hat{y}_i\\) and \\(y_i\\). Give an example for a scenario in which you could use regression analysis. Why is there an error term in regression? How does an error term differ from a residual? Consider the vector of error terms \\(\\epsilon\\) (an n \\(\\times\\) 1 matrix). How do you write \\(\\sum \\epsilon^2\\) in matrix notation? Please stop here and don’t go beyond this point until we have compared notes on your answers. Regression – Theory You are given the scatter plot in Figure 2.7 (taken from Gujarati &amp; Porter (2009)) along with the regression line. What general conclusion do you draw from this diagram? Is the regression line sketched in the diagram a population regression line or a sample regression line? Calculations with Matrices As indicated on Moodle, we will start working with matrices next week. To familiarise yourself with these and to get a better overview how to work with them, please work through the following exercises. Feel free to consult the “Introduction to Matrices” Section for this. First, answer these questions: What is a matrix? What does transposition do? What is the purpose of an identity matrix? Now, consider the following three matrices A, B, and C: \\[\\begin{equation*} A = \\begin{bmatrix} 9 &amp; 4 &amp; 11 \\\\ 6 &amp; 8 &amp; 3 \\\\ 14 &amp; 7 &amp; 9 \\\\ \\end{bmatrix} \\hspace{1cm} B = \\begin{bmatrix} 13 &amp; 8 &amp; 12 &amp; 2 \\\\ 1 &amp; 5 &amp; 15 &amp; 3 \\\\ \\end{bmatrix} \\hspace{1cm} C = \\begin{bmatrix} 25 &amp; 22 \\\\ 31 &amp; 19 \\\\ \\end{bmatrix} \\end{equation*}\\] What is the value in: Transpose \\(B\\) into \\(B^\\prime\\) using the following blank matrix. \\[\\begin{equation*} B^\\prime = \\begin{bmatrix} &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp;\\\\ \\end{bmatrix} \\end{equation*}\\] Solve \\(D\\) where \\(C \\times B = D\\) using the following blank matrix. \\[\\begin{equation*} D = \\begin{bmatrix} &amp; &amp; &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp; &amp; &amp;\\\\ \\end{bmatrix} \\end{equation*}\\] Solve \\(C^{-1}\\), showing your workings using the appropriate formula. \\[\\begin{equation*} C^{-1} = \\frac{\\:}{\\hspace{2.5cm}} \\begin{bmatrix} &amp; &amp; &amp; &amp; \\\\ &amp; &amp; &amp; &amp; \\\\ \\end{bmatrix} \\hspace{2.5mm}=\\hspace{2.5mm} \\begin{bmatrix} &amp; &amp; &amp; &amp; \\\\ &amp; &amp; &amp; &amp; \\\\ \\end{bmatrix} \\end{equation*}\\] Homework Familiarise yourself further with matrices by setting yourself two sample matrices, A and B (each should be a 2x2 matrix). Conduct the following operations: Multiply A and B Invert A and B Transpose A and B Multiply A with an Identity Matrix Multiply A with A\\(^{-1}\\). What is the result called? You can check your solutions with https://matrixcalc.org/en/. This is a great way to practice working with matrices until you are familiar with the procedure. Some of the content of this worksheet is taken from Reiche (forthcoming).↩︎ "],["worksheet-week-4.html", "Worksheet Week 4 Self-Assessment Questions8 Regression – Calculations Regression in R Solutions", " Worksheet Week 4 Self-Assessment Questions8 How does OLS fit the regression line? Why do we have to square the residuals for OLS? What are the advantages of working with matrices in regression analysis? Explain the concept of an identity matrix. Please stop here and don’t go beyond this point until we have compared notes on your answers. Regression – Calculations Consider the following data set: Plot the data in the above Table in a suitable scatter plot. Fit a line of best fit through the scatter plot (by eyeballing and a ruler). Assuming a regression model of the type \\(Y_{i}=\\beta_{0}+ \\beta_{1}X_{i}+\\epsilon_{i}\\), calculate the estimators for \\(\\beta_{0}\\) and \\(\\beta_{1}\\). Create a table like the one I used in the lecture. How do do the intermediary calculations in this table relate to the formulae for the coefficients? Calculate the regression coefficients \\(\\beta_{0}\\) and \\(\\beta_{1}\\) using matrices. Specify the SRF and interpret the estimators of \\(\\beta_{0}\\) and \\(\\beta_{1}\\). Regression in R Load the data set from Excel. Code library(readxl) incomedata &lt;- read_excel(&quot;files/Week 4/PO12Q_4.xlsx&quot;) You can also enter the values of a table manually using the matrix() function as follows: Code table &lt;- matrix(c(22,19,56,45,37,23,32,65,43,48, 700,650,2300,1900,2000,900,1000,2500,2800,1200), nrow=10,ncol=2) incomedata &lt;- data.frame(table) Run the regression in R as follows: Code regression &lt;- lm(income ~ age, data = incomedata) summary(regression) Call: lm(formula = income ~ age, data = incomedata) Residuals: Min 1Q Median 3Q Max -652.25 -102.92 6.53 142.21 584.39 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -53.092 304.716 -0.174 0.866011 age 39.695 7.325 5.419 0.000631 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 335.3 on 8 degrees of freedom Multiple R-squared: 0.7859, Adjusted R-squared: 0.7592 F-statistic: 29.37 on 1 and 8 DF, p-value: 0.0006314 Check your results from the first section. Solutions You can find the Solutions in the Downloads Section. Make up a data set like the one in this worksheet and pratice calculations. You can check your results either with R, or with the Excel sheet in the solutions if you want the intermidiary results. Some of the content of this worksheet is taken from Reiche (forthcoming).↩︎ "],["worksheet-week-5.html", "Worksheet Week 5 Self-Assessment Questions9 Mathematical Properties of OLS Goodness of Fit – Using R Goodness of Fit – By Hand Solutions", " Worksheet Week 5 Self-Assessment Questions9 Why do we need a measure to assess goodness of fit? How do you interpret R-Squared? Explain in your own words what the residual sum of squares (RSS) means. Explain one of the mathematical properties of OLS in your own words. Please stop here and don’t go beyond this point until we have compared notes on your answers. Mathematical Properties of OLS I showed in the lecture that the predicted values of y are uncorrelated with the residuals. Show mathematically that this is not the case for the error terms. Hint: Consider carefully Equation 2 on Slide 8. Goodness of Fit – Using R We will be using our WDI example again to explore model fit in R. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). Download the WDI_PO12Q.csv data set. Set your working directory and load the data set as an object called wdi. We will re-assess our question from Week 1, whether the level of GDP has an influence on life expectancy State the null and the alternative hypothesis (directional) Run the regression model. Code wdi &lt;- read.csv(&quot;files/Week 5/WDI_PO12Q.csv&quot;) attach(wdi) model &lt;- lm(lifeexp ~ gdppc) summary(model) Call: lm(formula = lifeexp ~ gdppc) Residuals: Min 1Q Median 3Q Max -17.445 -3.260 1.545 4.760 8.969 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.815e+01 5.797e-01 117.56 &lt;2e-16 *** gdppc 2.619e-04 2.515e-05 10.41 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 6.129 on 167 degrees of freedom (26 observations deleted due to missingness) Multiple R-squared: 0.3936, Adjusted R-squared: 0.39 F-statistic: 108.4 on 1 and 167 DF, p-value: &lt; 2.2e-16 Build the SRF and interpret the coefficients. Assess and interpret model fit, using “Multiple R-squared” which is equivalent to the R\\(^2\\) we discussed in the lecture. We have “only” covered the Estimate column in this output so far. We will be working towards interpreting the rest over the next few weeks. You can also extract specific blocks of the output table by placing brackets [] after the summary() function. For example summary()[1]. Try to extract the block containing model fit, like this: $r.squared [1] 0.3936356 Goodness of Fit – By Hand Using the data and calculations presented in the Table below, calculate the coefficient of determination, \\(r^{2}\\), with \\(\\hat{Y_{i}}= -53.1 + 39.7 X_{i}\\) Solutions You can find the Solutions in the Downloads Section. Some of the content of this worksheet is taken from Reiche (forthcoming).↩︎ "],["reading-week.html", "Reading Week", " Reading Week You know the drill. Reading week is not an institutionalised holiday, but I do expect you to put in about 10 hours of work for this module over the course of this week. Here are a few suggestions for activities to fill these 10 hours: Catch up on the reading Revise the material of Weeks 1-5 in preparation for the in-class test in Week 7. Go through the worksheets of Weeks 1-5 for the same reason. If you struggle with understanding the code, go through the worksheets and verbalise in plain English each code chunk. If you need help with what each of the functions means then you can find descriptions in the csv files that underpin the flashcards. These are available here. Revise all R functions up to this point. I have made a special flashcard section for this. "],["worksheet-week-7.html", "Worksheet Week 7 Self-Assessment Questions10 Regression – Standard Errors of Coefficients Regression – Hypothesis Testing &amp; Confidence Intervals Solutions", " Worksheet Week 7 Self-Assessment Questions10 Why do we need to calculate standard errors of estimators? Describe the relationship between confidence intervals and hypothesis testing. What does \\(\\sigma^2\\) represent substantively? Please stop here and don’t go beyond this point until we have compared notes on your answers. Regression – Standard Errors of Coefficients Using the following regression calculations, determine the size of the standard errors of \\(\\hat{\\beta}_{0}\\) and \\(\\hat{\\beta}_{1}\\) in tabular form in matrix form Regression – Hypothesis Testing &amp; Confidence Intervals Consider the following regression, where gdp indicates Gross Domestic Product (PPP) in 2005 US Dollars, and life indicates life expectancy at birth in years. I am running the regression with the first line and store the results in the object wdi. The second line asks R to display the detailed results for the regression. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). Code model1 &lt;- lm(gdppc ~ lifeexp, data = wdi) summary(model1) Call: lm(formula = gdppc ~ lifeexp, data = wdi) Residuals: Min 1Q Median 3Q Max -18457 -9877 -4187 4963 78242 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -94306.8 10406.7 -9.062 3.33e-16 *** lifeexp 1503.2 144.4 10.412 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 14690 on 167 degrees of freedom (26 observations deleted due to missingness) Multiple R-squared: 0.3936, Adjusted R-squared: 0.39 F-statistic: 108.4 on 1 and 167 DF, p-value: &lt; 2.2e-16 Formulate the null and alternative hypotheses which is tested in this model. Build the regression function. Is the coefficient significant? Interpret the coefficients. How would you interpret the coefficient if it was insignificant? Think carefully about what an insignificant result means in plain English to answer this question. Plot the regression function in a suitable diagram using ggplot. Explain how the t-value for life is obtained. What do our results mean for the hypotheses? What does the value of “Multiple R-Squared” (this is equivalent to the R-Squared we calculated by hand last week) mean? Calculate the 95% confidence intervals for the coefficient life and the intercept. Compare your results to the R output below. Find two explanations in the output for why the coefficient for life is statistically significant at the 5% level? Code confint(model1,level = 0.95) 2.5 % 97.5 % (Intercept) -114852.512 -73761.11 lifeexp 1218.183 1788.24 Solutions You can find the Solutions in the Downloads Section. Some of the content of this worksheet is taken from Reiche (forthcoming).↩︎ "],["additional-exercises.html", "Additional Exercises Load Packages and data11 Inspect your data Preliminary Analysis Visualisation Visualisation 2.0 Saving the Scatterplot Regression Analysis (yes, finally) Interpretation Exporting the Results Comparing models Solutions", " Additional Exercises Load Packages and data11 Before starting, we need to load libraries and install packages if not already installed. In these exercises we will be using the following packages: haven ggplot2 stargazer Set working directory and load the data. The file is on Moodle. It’s called simd.csv and it’s the “Scottish Index of Multiple Deprivation”. More details here: https://www.gov.scot/collections/scottish-index-of-multiple-deprivation-2020/ Inspect your data Here you can use several basic functions. The dataset does not contain too many variables, so you can start by using names(), str(), dim(), etc. The function dim() is new. What does it do? Preliminary Analysis Now that you have a preliminary idea of the structure of the dataset, you can select two variables and test a possible relationship. The topic today is bivariate linear regression analysis, so remember that the outcome variable needs to be continuous. Let’s say we want to look at the relationship between alcohol consumption and mortality rate (yes, not a very funny topic, but interesting nonetheless). The two variables are, respectively, alcohol and mortality (rather intuitive this time). Now, formulate the working (alternative) and the null hypothesis. Write them down. H\\(\\pmb{_0}\\): H\\(\\pmb{_1}\\): Which is your dependent variable? Run a frequency table on the mortality variable. What is the level of measurement? Do the same for the other variable. And guess what is the level of measurement. Visualisation Let’s start with the visualisation of the relationship between the two variables. Use a scatterplot to visualise the relationship and add the regression line. You can use ggplot, but also the standard plot() function. Improve the graph by: Adding a regression line. Adding up a relevant title, also possibly a subtitle. Adding axes labels and making them readable. Remove the grid in the background. If you have done everything correctly, you should see that the dots are rather concentrated in the bottom left corner of the scatterplot with some outliers far away from the cloud of our data. It is not a big deal, but we might want to get rid of the outliers and this way improve our visualisation. There are several ways to do that, of course. But let’s say we want to transform our variables, excluding all values over a certain point. For instance, we want to exclude the values above 750 of our alcohol variable and above 500 for our mortality variable. How would you do that? There are – of course – several solutions. One could be, to create a new datset, subsetting the original. Another solution could be to create a new variable telling R to transform all the values above our treshold in NA. Try to find an apply the appropriate code. Use Google if necessary, it helps a lot. Visualisation 2.0 Now, visualise the relationship using the new variables. What can you see? You can improve the scatterplot using a series of arguments (e.g., alpha) in the geom_point() function in ggplot. Try to improve the Aesthetics of the scatterplot playing with alpha, for instance. (see: https: //www.rdocumentation.org/packages/ggplot2/versions/3.4.0/topics/geom_point). Also, you can draw a vertical and horizontal line corresponding to the mean of your variables using geom_hline and geom_vline. You can thus check if the regression line passes through the mean of X and Y. (see: https://www.rdocumentation.org/packages/ggplot2/versions/0.9.1/topics/geom_hline). Remember that Google is your best friend when you learn to code. And after that as well. No one actually remembers all the functions and all their argument. The secret is to know how to google the things you need. Saving the Scatterplot You can also save a graph as .png, .JPG (even .pdf) that you can then import in a word document. Although there are many way to use your R output, saving a graph might be sometimes useful. Use the function ggsave() to save your scatterplot. Again, there are tons of examples online, google it. You first need to store the graph in an object. Regression Analysis (yes, finally) Now we can finally run a linear regression with mortality as the outcome variable and alcohol as the predictor using the lm() function. Store the results in an object called model and visualise the regression output using summary(). Use the reduced data set without outliers. Call: lm(formula = mortality ~ alcohol, data = simred) Residuals: Min 1Q Median 3Q Max -122.69 -22.52 -4.71 17.27 377.77 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 78.155160 0.619648 126.13 &lt;2e-16 *** alcohol 0.208270 0.004476 46.53 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 35.61 on 6956 degrees of freedom Multiple R-squared: 0.2374, Adjusted R-squared: 0.2373 F-statistic: 2165 on 1 and 6956 DF, p-value: &lt; 2.2e-16 You can also extract specific blocks of the output table. One way of doing it is to use the brackets [] after the summary() function. For example summary()[8]. Try to extract the block of Coefficients from the table, like this: Code summary(model)[4] $coefficients Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 78.1551599 0.619648419 126.12823 0 alcohol 0.2082697 0.004476011 46.53021 0 Interpretation Interpret the results, starting with model evaluation. Is the p-value of the F-statistics statistically significant? We will be discussing this in our following lectures. How much variation in the outcome variable does the model explain? What does this tell us about the model? What’s the value of the slope? What does it mean? What’s the value of the regression coefficient? How do we interpret it? Is it statistically significant? What does it mean in practice? Interpret the results (in plain language) referring to the hypothesis you formulated above. Exporting the Results As for the graphs, you can also export and save the results of the regression model in a Word table. To do that you can use the stargazer package. Try and export the table. The function needs to contain, in order: the name of the R object where you stored the regression results, the option header=F to suppress the annoying immortalisation of the author, the option type=\"html\", and the option out=\"documentname.doc\" which places a word document with that file name in your working directory. Should you use MS Word to write your essay and your essay is saved in your working directory, do not save the table document under the same name as your essay, as R will overwrite it and it will be gone forever. You can improve the table in many ways. For example, you need to replace the variable names with the variable labels, You could add a name of the model and suppress unneeded statistics (see https://www.rdocumentation.org/packages/stargazer/versions/5.2.3/topics/stargazer_stat_code_list). Comparing models You can now run another regression model with a different independent variable. Can you compare your original model with the new one? How? How do you know which independent variable is doing a better job in explaining your dependent variable? Solutions You can find the Solutions in the Downloads Section. These exercises were originally written by Oleksiy Bondarenko who taught the module in 2022/23. I have slightly altered them in subsequent years.↩︎ "],["worksheet-week-8.html", "Worksheet Week 8 Self-Assessment Questions12 Multiple Regression in R – Guided Example Multiple Regression in R – Independent Analysis Solutions Homework", " Worksheet Week 8 Self-Assessment Questions12 Compare bivariate regression and multiple regression. Give an example of the relationship in which you could apply multiple linear regression. How do you interpret partial slope coefficients? How do you interpret adjusted R-Squared in regression analysis? Please stop here and don’t go beyond this point until we have compared notes on your answers. Multiple Regression in R – Guided Example Download the WDI_PO12Q.csv data set. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). Put it into an appropriate working directory for this seminar and create a dedicated RScript and save it into the same working directory. Import the data set into R: Once again, here is the overview of the variables available and their respective label in Table 3: Table 3: WDI Codebook variable label Country Name Country Name Country Code Country Code year year gdppc GDP per capita (constant 2010 US$) gdpgrowth Absolute growth of per capita GDP to previous year (constant 2010 US Dollars) enrl_gross School enrollment, primary (% gross) enrl_net School enrollment, primary (% net) agri Employment in agriculture (% of total employment) (modeled ILO estimate) slums Population living in slums (% of urban population) telephone Fixed telephone subscriptions (per 100 people) internet Individuals using the Internet (% of population) tax Tax revenue (% of GDP) electricity Access to electricity (% of population) mobile Mobile cellular subscriptions (per 100 people) service Services, value added (% of GDP) oil Oil rents (% of GDP) natural Total natural resources rents (% of GDP) literacy Literacy rate, adult total (% of people ages 15 and above) prim_compl Primary completion rate, total (% of relevant age group) infant Mortality rate, infant (per 1,000 live births) hosp Hospital beds (per 1,000 people) tub Incidence of tuberculosis (per 100,000 people) health_ex Current health expenditure (% of GDP) ineq Income share held by lowest 10% unemploy Unemployment, total (% of total labor force) (modeled ILO estimate) lifeexp Life expectancy at birth, total (years) urban Urban population (% of total population) polity5 Combined Polity V score Let’s take the example from Week 7 back up. First re-run the regression I used back then. Code wdi_life &lt;- lm(gdppc ~ lifeexp, data = wdi) summary(wdi_life) Call: lm(formula = gdppc ~ lifeexp, data = wdi) Residuals: Min 1Q Median 3Q Max -18457 -9877 -4187 4963 78242 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -94306.8 10406.7 -9.062 3.33e-16 *** lifeexp 1503.2 144.4 10.412 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 14690 on 167 degrees of freedom (26 observations deleted due to missingness) Multiple R-squared: 0.3936, Adjusted R-squared: 0.39 F-statistic: 108.4 on 1 and 167 DF, p-value: &lt; 2.2e-16 Interpret the coefficients. Now we use a different regressor, say “Urban population (% of total)”. Specify the null and the alternative hypotheses. Code wdi_urban &lt;- lm(gdppc ~ urban, data = wdi) summary(wdi_urban) Call: lm(formula = gdppc ~ urban, data = wdi) Residuals: Min 1Q Median 3Q Max -28588 -10681 -3110 6863 152303 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -16983.43 3872.34 -4.386 1.98e-05 *** urban 542.03 61.74 8.779 1.42e-15 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 19120 on 176 degrees of freedom (17 observations deleted due to missingness) Multiple R-squared: 0.3045, Adjusted R-squared: 0.3006 F-statistic: 77.07 on 1 and 176 DF, p-value: 1.417e-15 Interpret the coefficients. What does this mean for the hypotheses? If we want to assess the influence of both independent variables together, we type: Code wdi_joint &lt;- lm(gdppc ~ lifeexp + urban, data = wdi) summary(wdi_joint) Call: lm(formula = gdppc ~ lifeexp + urban, data = wdi) Residuals: Min 1Q Median 3Q Max -22570 -8825 -2143 5594 74445 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -74786.14 10690.13 -6.996 6.17e-11 *** lifeexp 1012.17 172.70 5.861 2.41e-08 *** urban 273.74 59.13 4.629 7.37e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 13860 on 166 degrees of freedom (26 observations deleted due to missingness) Multiple R-squared: 0.463, Adjusted R-squared: 0.4565 F-statistic: 71.55 on 2 and 166 DF, p-value: &lt; 2.2e-16 Interpret the coefficients. Bear in mind for your interpretation that these are partial slope coefficients! Because I am nice, I am producing an overview of all three regressions in the following table:     Dependent variable: per capita GDP (1) (2) (3) Life Expectancy 1,503.211*** 1,012.168*** (144.371) (172.696) Urbanisation 542.033*** 273.735*** (61.743) (59.134) Constant -94,306.810*** -16,983.430*** -74,786.150*** (10,406.730) (3,872.336) (10,690.130) Observations 169 178 169 R2 0.394 0.305 0.463 Adjusted R2 0.390 0.301 0.456 Note: p&lt;0.1; p&lt;0.05; p&lt;0.01     Drawing on what you have learned about the stargazer package in the additional exercises last week, try to replicate this table. How have the slope coefficients changed? Why? Which model explains the level of GDP best? Why? Specify the SRF for Model 3, paying special attention to notation. Now assume, we want to know whether education has a bearing on the level of GDP. We call: Code wdi_lit &lt;- lm(gdppc ~ literacy, data = wdi) and also add it to the joint model: Code wdi_joint1 &lt;- lm(gdppc ~ lifeexp + urban + literacy, data = wdi) This should lead to these results:     Dependent variable: per capita GDP (1) (2) (3) (4) (5) Life Expectancy 1,503.211*** 1,012.168*** 973.985** (144.371) (172.696) (411.375) Urbanisation 542.033*** 273.735*** 227.126** (61.743) (59.134) (83.427) Literacy 258.407** -221.731 (97.381) (142.455) Constant -94,306.810*** -16,983.430*** -74,786.150*** -12,967.000 -55,246.840*** (10,406.730) (3,872.336) (10,690.130) (8,529.810) (19,311.130) Observations 169 178 169 40 39 R2 0.394 0.305 0.463 0.156 0.497 Adjusted R2 0.390 0.301 0.456 0.134 0.454 Note: p&lt;0.1; p&lt;0.05; p&lt;0.01     In Model 5 the coefficient for literacy has turned insignificant. Reproduce the results in Table 4 to find out which variable takes away the significance.     Dependent variable: per capita GDP (1) (2) (3) Literacy 258.407** -223.305 28.390 (97.381) (154.620) (99.706) Life Expectancy 1,483.785*** (397.567) Urbanisation 315.375*** (77.633) Constant -12,967.000 -77,851.340*** -12,399.610* (8,529.810) (18,924.060) (7,189.937) Observations 40 39 40 R2 0.156 0.390 0.417 Adjusted R2 0.134 0.357 0.385 Note: p&lt;0.1; p&lt;0.05; p&lt;0.01     What can we conclude from this investigation? Does the variable infant have the same effect? What do you conclude from this? Which measurement explains GDP better, life or infant?     Dependent variable: per capita GDP (1) (2) Life Expectancy 1,503.211*** (144.371) Infant Mortality -524.111*** (73.885) Constant -94,306.810*** 26,467.130*** (10,406.730) (2,257.385) Observations 169 178 R2 0.394 0.222 Adjusted R2 0.390 0.218 Note: p&lt;0.1; p&lt;0.05; p&lt;0.01     Multiple Regression in R – Independent Analysis Before you start with these, please pause and let Flo/Luis know that you are done. We will compare notes on your answers up to this point, to make sure that you are on the right track for the independent exercises. Use the wdi data frame. Set polity5 as the dependent variable, and choose three sensible variables which you believe could influence democracy. Note that the Polity V Score codes regimes from -10 (indicating perfect autocracy) to +10 (indicating perfect democracy). State the null- and alternative hypotheses for each of the independent variables chosen. Plot two of the bivariate models in a scatter plot (black points) with fitted regression line (in red). Use base R, or ggplot. Does the direction of influence agree with your hypotheses? Run all possible regression models. Put the results into a suitable table, noting the p-values of each coefficient in the brackets underneath. Try all different combinations of your variables to see which of the three is the best to explain democracy. Specify the Sample Regression Function (SRF) for models 1, 4, and 7. Interpret the intercept and one of the slope coefficients in models 1, 4, and 7. Interpret the model fit measure for models 1, 4, and 7. What do we conclude with respect to the hypotheses stated in Exercise 2 from this analysis? Collate a PowerPoint (Keynote) presentation with one slide for each of the preceding eight points. We will discuss this in Week 9. Solutions You can find the Solutions in the Downloads Section. Homework For next week, please Finish the independent exercises. Read one of the following two articles: Arat, Zehra. 1988. “Democracy and Economic Development: Modernization Theory Revisited”. Comparative Politics 21(1): 21-36. Heger, Lindsay, and Idean Salehyan. 2007. “Ruthless Rulers: Coalition Size and the Severity of Civil Conflict.” International Studies Quarterly 51(2): 385-403. Identify the following components: Research Question Theory Hypotheses Method Results Conclusion (Answer to the research question) What do you like / dislike about the article? Do you have any points of critique? Some of the content of this worksheet is taken from Reiche (forthcoming).↩︎ "],["worksheet-week-9.html", "Worksheet Week 9 Group Work – Self-Reflection13 Working with Regression Analysis Going Further Transformation of Variables Solutions", " Worksheet Week 9 Group Work – Self-Reflection13 How does the concept of the conditional expected value relate to the interpretation of coefficients in multiple regression? How do you select variables for a multiple regression model? Why do we apply non-linear transformations to variables? How do you interpret the effect of a logarithmized variable? Give an example for each of the variable transformations we discussed in the lecture. Please stop here and don’t go beyond this point until we have compared notes on your answers. Working with Regression Analysis We will be using the “crime.csv” data available in the Downloads Section to analyse attitudes and experiences of crime in England and Wales. The data set contains several variables relating to questions asked about experience and perceptions of crime to a representative sample along with demographic details on the respondents. Data are taken from University of Manchester, Cathie Marsh Institute for Social Research (CMIST), UK Data Service, Office for National Statistics (2019). For variable labels, please consult the Crime Data Code Book. Data Prep Each respondent was randomly assigned to a different module, indicated by split and only asked a subsection of the questions. The antisocx variable is part of module A and asks for a score from respondents on how much antisocial behaviour is in the neighbourhood. Create a new data set for those who were chosen for the ‘A’ module. Call this crime.a. Data Analysis Previous research has suggested men perceive more antisocial behaviour in rural areas than urban areas. Create a linear model using only male respondents from crime.a with the dependent variable antisocx and the independent variable rural2. Do your findings support previous research? Test the same model using only women. How do the two models differ? The wburgl variable asks respondents how worried they are about being burgled with answers ranging from “Very worried” to “Not at all worried” along with “Not applicable” and “Don’t know.” Recode those with “Not applicable” or “Don’t know” as NAs. b.Using agegrp7 and wburgl as continuous variables, test the hypothesis that older people are more worried about being burgled. Using a dummy variable test whether those over 65 have are more worried about burglary then those who are younger. Using dummies test whether any of the age groups differ significantly from the youngest age group. What does the intercept in each of the three models represent? Going Further I have written these exercises so that you can practise in R a little more. These are a bt more demanding, however.If you skip this section, please make sure to do the exercises in the next section, as this taps into the variable transformations we explored in the lecture. There are five variables which ask how worried the respondent is about being the victim of various crimes: Create an additive variable called worry from these variables so that a score of 0 indicates the respondent answered all “Not at all worried” and a score of 15 indicates the respondent answered all “Very worried.” (Tip: Make sure to clean the variables for NAs). What are the mode, mean and median for worry? Describe the variable educat3. How could it be modified to be used as a continuous variable? Using educat3 as both a continuous and factor variable evaluate the statement “Worry about being a victim of crime is higher in those with lower education levels.” What are the \\(R^2\\) values for the two models calculated? Which is higher? Does this make that model better than the other? Calculate \\(97.5\\%\\) confidence intervals for the coefficients for those with GCSEs and those with Degrees. What does this tell you? Transformation of Variables This Section uses the london_exercises data set available in the Downloads Section. Data are taken from London Data Store (2013). This document provides a full codebook. Unemployment rate, defined as the ratio of people in full time employment to population of working age is often said to be related to crime. Generate an unemployment rate variable for each of the wards. It is theorised that unemployment is a driving factor behind crime rates. Plot a scatter graph with unemployment rate, crime rate, and the regression line that may be used to evaluate the theory. Describe the plot and the best fit line. Plot the graph again excluding wards with a crime rate greater than 500. Describe the plot and the best fit line. Plot another graph excluding wards with a crime rate of over 500 with the crime rate log transformed. Describe the plot and the best fit line. Build both models. Interpret both including the effect size. Which model fits the data better? Solutions You can find the Solutions in the Downloads Section. All exercises are a reproduction from Reiche (forthcoming).↩︎ "],["worksheet-week-10.html", "Worksheet Week 10 Self-Assessment Questions Testing the Classical Linear Assumptions The Gauss-Markov Theorem Solutions", " Worksheet Week 10 Self-Assessment Questions How do the mathematical properties of OLS (Week 5) differ from the Classical Linear Assumptions? Why is observed heteroscedasticity a problem that needs addressing? What happens in a model with (multi-)collinearity? Does the assumption of linearity in the Gauss-Markov Theorem preclude non-linear transformations? Why / why not? Please stop here and don’t go beyond this point until we have compared notes on your answers. Testing the Classical Linear Assumptions For this worksheet we will be using the london data set from the lectures, this time with the following variables: Data are taken from GOV.UK (2013), London Data Store (2010), and House of Commons Library (n.d.). Homoscedasticity Load the data set london_11.csv as an object called london Subset the data to a random sample as follows: Code set.seed(123) london_sam &lt;- sample_frac(london, 0.65, replace=FALSE) Regress GCSE scores on income and interpret the results. Code model1 &lt;- lm(gcse ~ income, data=london_sam) Breusch-Pagan Test by Hand Extract the residuals from model 1 and store their squared values in a new object called ressq. Code ressq &lt;- resid(model1)^2           b. Regress the squared residuals on the original independent variable. Code model1res &lt;- lm(ressq~income, data=london_sam)           c. Store the number of observations of this new model in an object called N. Code N &lt;- nobs(model1res)           d. Obtain the model fit measure R\\(^2\\) for this model.           e. Calculate the test-statistic for the Breusch-Pagan test as the product of N and R\\(^2\\). Code chisq &lt;- 0.001857*N           f. Conduct a Chi-Squared test with one degree of freedom. Code pchisq(chisq, df=1, lower.tail=FALSE) [1] 0.7676653 Breusch-Pagan Test with the lmtest package. Install and load the lmtest package           b. Call Code bptest(model1)           c. Compare the results with the results obtained in Exercise @ref{ex:homo4}. Heteroscedasticity Now let’s introduce heteroscedasticity: Code london_heterosc &lt;- filter(london, income&lt;28000 | income&gt;100000)           b. Estimate a new model, and note the significance of coefficients. Code model2 &lt;- lm(gcse ~ income, data=london_heterosc)           c. Conduct a Breusch-Pagan Test with the lmtest package.           d. Install and load the sandwich package. Code library(sandwich)           e. The sandwich package replaces \\(\\Omega\\) with a new diagonal which takes into account                heteroscedasticity. The default is HC3 – if you ever work with somebody using Stata then                you need to replace this with HC1 to obtain the same results. Conduct a significance test with                robust standard errors (with the sandwich function coeftest): Code coeftest(model2, vcov = vcovHC(model2, type=&quot;HC3&quot;))           f. Compare the significance to the results in 6b and explain the reason for the difference.           g. Estimate a model of your own choice with gcse as your dependent variable.           h. Conduct the Breusch-Pagan test                i. by hand                ii. with the lmtest package (Multi-)Collinearity14 In this Section, we will be testing for collinearity. We can do so with correlation analysis, which assesses to what degree two variables vary together. As such, this method is limited to pairwise comparisons between variables. It is conceivable, and indeed often the case, however, that one variable is functionally related to two or more other independent variables, such as \\[\\begin{equation*} x_{1,i} = 0.2 x_{2,i }- 1.7 x_{3,i} \\end{equation*}\\] We refer to this situation as multicollinearity. In order to detect it, we need to test for the functional dependence of each independent variable on the remaining independent variables in the model. We can do so by employing secondary regression models, not unlike in the Breusch-Pagan Test (see lecture slides). We specify K secondary regression models, each adopting one of our K independent variables as its dependent variable. Let us specify such a function for \\(x_1\\): \\[\\begin{equation*} x_{1,i} = \\alpha_0 + \\alpha_1 x_{2,i} + \\alpha_2 x_{3,i} + ... + \\alpha_{K-1} x_{K,i} + v_i \\end{equation*}\\] where \\(\\alpha\\) denotes our new regression coefficients, and \\(v_i\\) represents a random error term. For the remaining independent variables, the functions would look as follows: \\[\\begin{align*} x_{2,i} &amp;= \\alpha_0 + \\alpha_1 x_{1,i} + \\alpha_2 x_{3,i} + \\alpha_3 x_{4,i} + ... + \\alpha_{K-1} x_{K,i} + v_i \\\\ x_{3,i} &amp;= \\alpha_0 + \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{4,i} + ... + \\alpha_{K-1} x_{K,i} + v_i \\\\ \\vdots \\\\ x_{K,i} &amp;= \\alpha_0 + \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + ... + \\alpha_{K-1} x_{K-1,i} + v_i \\end{align*}\\] In order to quantify how well each of the K regression functions explains the respective independent variable, we are going to use Adjusted R-Squared. We will note the \\(R^2\\) of each individual regression as \\(R_j^2\\) where j runs from 1 to K, or \\(j=1,...,K\\). \\(R_j^2\\) in itself already provides useful information, but we can do better than this. We can use \\(R_j^2\\) to develop a measure which tells us how much larger the observed variance of a coefficient is compared to a scenario in which the variable was totally functionally independent from the other independent variables in the model. We call this measure variance inflation factor and define it as follows: \\[\\begin{equation} \\text{VIF}_j = \\frac{1}{1-R_j^2} \\end{equation}\\] Its size is solely determined by \\(R_j^2\\). The better a model explains the respective independent variable, the closer \\(R_j^2\\) will be to one, increasing the size of VIF\\(_j\\). A commonly adopted threshold for classing a variable as (multi-)collinear is VIF=10. This threshold is completely arbitrary, but has nonetheless managed to establish itself in regression analysis. We will now use london_sam data frame to put theory into practice. Regress GCSE scores on and in a multiple regression model. Interpret the results. Code model3 &lt;- lm(gcse ~ income + idaci, data=london_sam) Install and load the package. Code library(car) Calculate the Variance Inflation Factor (VIF) for this model as follows: Code vif(model3) Interpret the results. Regress GCSE scores on houseprice. Store the results in an object called model4. Note the significance of the slope coefficient and interpret the results. Let’s introduce some collinearity by estimating the following model: Code model5 &lt;- lm(gcse ~ income + houseprice, data=london_sam) Calculate the VIF for model 5. Interpret the results. Drawing on the results of Exercise 7, explain the significance of the slope coefficients of Model 1 (Exercise 3 in the previous section) and Model 4 (Exercise 6 of this section). The Gauss-Markov Theorem Explain in your own words, what BLUE means. According to Malinvaud, the assumption that \\(E(\\epsilon_{i}|X_{i})=0\\) is quite important. To see this, consider the PRF: \\(Y=\\beta_{0}+\\beta_{1}X_{i}+\\epsilon_{i}\\). Now consider two situations: (1) \\(\\beta_{0}=0\\), \\(\\beta_{1}=1\\) and \\(E(\\epsilon_{i})=0\\); and (2) \\(\\beta_{0}=1\\), \\(\\beta_{1}=0\\) and \\(E(\\epsilon_{i})=X_{i}-1\\). Now take the expectation of the PRF conditional upon \\(X\\) in those two cases, and see if you agree with Malinvaud about the significance of the assumption \\(E(\\epsilon_{i}|X_{i})=0\\).15 Solutions You can find the Solutions in the Downloads Section. This discussion is a verbatim reproduction of Reiche (forthcoming).↩︎ Exercise taken from Gujarati &amp; Porter (2009)↩︎ "],["downloads.html", "Downloads Documents Data Sets R Scripts", " Downloads Yes, all solutions and all RScripts are available to you without the silly time restriction I imposed in term 1. The reason is that I have come to realise that I am operating a module in a university, and not in a kindergarten. Of course, you can download and look at the solutions before you have given the exercises a go yourself first. By all means, cheat. But I can’t promise you that you will learn very much. It’s your choice. Documents PO12Q Bibliography Statistical Tables Week 1 Worksheet Solutions Week 2 Worksheet Solutions Week 4 Worksheet Solutions Week 4 Regression Calculations Week 5 Regression Calculations Week 7 Worksheet Solutions Week 7 Regression Calculations Week 7 Solutions to Additional Exercises Week 9 Crime Data Code Book Week 9 london_exercises Code Book Week 10 Worksheet Solutions Data Sets WDI_PO12Q.csv PO12Q_4.xslx crime.csv london_exercises.csv london_11.csv R Scripts Week 3 R Solutions Week 8 R Solutions Week 9 R Solutions Week 10 R Solutions "],["list-of-references.html", "List of References", " List of References Boix, C., Miller, M., &amp; Rosato, S. (2018). Boix-Miller-Rosato Dichotomous Coding of Democracy, 1800-2015 (Version V3). Harvard Dataverse. GOV.UK. (2013). National Statistics: Income and tax by Parliamentary constituency. available online at https://www.gov.uk/government/statistics/income-and-tax-by-parliamentary-constituency-2010-to-2011. Gujarati, D. N., &amp; Porter, D. C. (2009). Basic Econometrics (Fifth International Edition). New York: McGraw-Hill. House of Commons Library. (n.d.). Data Dashboard. available online at https://commonslibrary.parliament.uk/type/data-dashboard/. London Data Store. (2010). London Parliamentary Constituency Profiles 2010. available online at https://data.london.gov.uk/dataset/london-parliamentary-constituency-profiles. London Data Store. (2013). Ward Profiles and Atlas. available online at https://data.london.gov.uk/dataset/ward-profiles-and-atlas. Marshall, M. G., &amp; Gurr, T. R. (2020). Polity V Project: Political Regime Characteristics and Transitions, 1800-2018. available online at http://www.systemicpeace.org/inscrdata.html. Reiche, F. (forthcoming). Introduction to Quantitative Methods in the Social Sciences. Oxford: Oxford University Press. University of Manchester, Cathie Marsh Institute for Social Research (CMIST), UK Data Service, Office for National Statistics. (2019). Crime Survey for England and Wales, 2013-2014: Unrestricted Access Teaching Dataset. available online at https://doi.org/10.5255/UKDA-SN-8011-1. World Bank. (2024). World Development Indicators, 21.02.2024. available online at https://datacatalog.worldbank.org/dataset/world-development-indicators. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
