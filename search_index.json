[["index.html", "PO12Q: Seminar Companion Preface", " PO12Q: Seminar Companion Dr Flo Reiche Department of Politics and International Studies University of Warwick Last Updated 11 March, 2025 Preface This is the online companion to the seminars on PO12Q. This replaces the physical worksheets which we work through in seminars for a few reasons: it provides a more seamless, integrated appearance you can copy / paste code directly from the code chunks in this online companion, whereas doing so from a pdf (on Moodle) tends to lead to problems with character encoding. it adds a lot of other functionality a pdf could only dream of it is environmentally friendlier I hope you find this useful! "],["companion-features.html", "Companion Features", " Companion Features You will find embedded in the text four different types of boxes which serve different purposes: This box appears whenever I want you to stop at a particular point in the worksheet and to flag up to me or Luis that you are done. Some explanations that will hopefully make your work with this webpage or learning the material itself easier. To help you a bit along the way through the module, I have recorded a few videos. A brief question which tests your understanding of the previous material. This appears when you need to be careful with your coding in R to avoid problems. "],["accessibility.html", "Accessibility", " Accessibility For those of you who prefer a dark background, like me, you can select this option from the menu at the top of the page. Click the ‚ÄúA‚Äù symbol, and then you can choose between ‚Äúwhite‚Äù, ‚Äúsepia‚Äù, or ‚Äúnight‚Äù. The companion uses the font ‚ÄúLexend‚Äù. Lexend fonts are intended to reduce visual stress and so improve reading performance. Initially they were designed with dyslexia and struggling readers in mind, but Bonnie Shaver-Troup, creator of the Lexend project, soon found out that these fonts are also great for everyone else. "],["methods-methods-methods.html", "Methods, Methods, Methods Data Prep Video and RScript", " Methods, Methods, Methods Whenever I introduce you to a new method on this module, you will find this section here on the companion. It will contain an RScript for some preliminary data preparation. This is not an actual part of introducing the method, but you are certainly encouraged to read it and to try and understand it. These sections will work with the American National Election Studies (ANES), and to be more precise with the pilot survey conducted before the 2020 presidential election. You can download the required data set by following this link. The actual data set itself is available here. Data Prep Place the ANES data in a folder which you will be using as a working directory for this session. Open the ‚ÄúCode for Data Preparation‚Äù below, and copy this into an RScript. Remember to adjust the working directory with the setwd() command at the beginning. Then run the RScript and you will be ready to proceed to the video. Code for Data Preparation ###################################### # MMM - Week 1 - Data Preparation ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes.csv&quot;) # Get rid of missing values for variables used in analysis today ## 999 is equivalent to NA, so needs to be recoded anes$fttrump1 &lt;- with(anes, replace(fttrump1, fttrump1 == 999, NA)) anes &lt;- filter(anes, !is.na(fttrump1), !is.na(sex)) # turn support for Trump `fttrump1` into ordered factor with three levels anes &lt;- anes %&gt;% mutate(trump= ordered( cut(fttrump1, breaks=c(0, 33, 66, 100), labels=c(&quot;low&quot;,&quot;medium&quot;,&quot;high&quot;)))) # Label variable `sex` anes$sex &lt;- factor(anes$sex) anes &lt;- anes %&gt;% mutate(sex= recode(sex,&quot;1&quot;=&quot;Male&quot;, &quot;2&quot;=&quot;Female&quot;)) # save data set for use in video write.csv(anes, &quot;anes_week1.csv&quot;) You can copy the code from this page by hovering over the code chunk and clicking the icon in the top-right hand corner. You can then paste it into your RScript. Video and RScript You can find the video introducing you to this week‚Äôs method by way of a worked example below. You can also access the code I am typing up in the video in the ‚ÄúCode for Data Analysis‚Äù section. I would encourage you to type it yourself, though, as then code tends to better sink into the depths of your brain üòâ Code for Data Analysis ###################################### # MMM - Week 1 - Crosstabulations ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes_week1.csv&quot;) anes$sex &lt;- as.factor(anes$sex) anes$trump &lt;- as.factor(anes$trump) # Tabulate relationship between sex and support for Trump table(anes$sex,anes$trump) prop.table(table(anes$sex,anes$trump)) prop.table(table(anes$sex,anes$trump), margin = 1) # save table for analysis trumpsex &lt;- table(anes$sex,anes$trump) trumpsex xsq &lt;- chisq.test(trumpsex, correct=FALSE) xsq # display observed and expected values xsq$expected xsq$observed Cross Tabulations in R "],["worksheet-week-1.html", "Worksheet Week 1 Self-Assessment Questions1 Calculations by Hand Cross-Tabulations in R Homework for Week 2 Solutions", " Worksheet Week 1 Self-Assessment Questions1 What do cross-tabulations do? Can we use continuous variables for cross-tabulations? What are the strengths and weaknesses of cross-tabulations? Why do we calculate the \\(\\chi^2\\)-value as \\(\\chi^{2} = \\Sigma \\frac{(f_{o}-f_{e})^{2}}{f_{e}}\\) ? How does the \\(\\chi^2\\) distribution differ from the t- and normal distribution? Please stop here and don‚Äôt go beyond this point until we have compared notes on your answers. Calculations by Hand I have given you an example of a cross-tabulation in the lecture. Consider the following Table: Calculate the Expected Values and fill in the following table: Calculate the \\(\\chi^{2}\\)-value How many degrees of freedom does this table have? Why? Using the \\(\\chi^2\\) Table, what is the p-value? Are mode of transport and year of study independent in the population? Cross-Tabulations in R If you have joined PO12Q without suffering through PO11Q, then please work through Weeks 5 and 7 of PO11Q before proceeding with the present material: PO11Q, Week 5 PO11Q, Week 7 Data Set We are working with the World Development Indicators this week. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). For more information on the democracy coding by Boix et al.¬†please download and read the corresponding paper. Download the data WDI_PO12Q.csv and place it in a new working directory for this week The variables we will be working with today are as follows: Table 1: WDI Codebook variable label Country Name Country Name Country Code Country Code year year democracy 0 = Autocracy, 1 = Dictatorship (Boix et al., 2018) gdppc GDP per capita (constant 2010 US$) gdpgrowth Absolute growth of per capita GDP to previous year (constant 2010 US Dollars) enrl_gross School enrollment, primary (% gross) enrl_net School enrollment, primary (% net) agri Employment in agriculture (% of total employment) (modeled ILO estimate) slums Population living in slums (% of urban population) telephone Fixed telephone subscriptions (per 100 people) internet Individuals using the Internet (% of population) tax Tax revenue (% of GDP) electricity Access to electricity (% of population) mobile Mobile cellular subscriptions (per 100 people) service Services, value added (% of GDP) oil Oil rents (% of GDP) natural Total natural resources rents (% of GDP) literacy Literacy rate, adult total (% of people ages 15 and above) prim_compl Primary completion rate, total (% of relevant age group) infant Mortality rate, infant (per 1,000 live births) hosp Hospital beds (per 1,000 people) tub Incidence of tuberculosis (per 100,000 people) health_ex Current health expenditure (% of GDP) ineq Income share held by lowest 10% unemploy Unemployment, total (% of total labor force) (modeled ILO estimate) lifeexp Life expectancy at birth, total (years) urban Urban population (% of total population) polity5 Combined Polity V score Loading the Data setwd(&quot;~/PO12Q/Seminars/PO12Q_Seminar_Week 1&quot;) wdi &lt;- read.csv(&quot;WDI_PO12Q.csv&quot;) You can copy the code from this page by hovering over the code chunk and clicking the icon in the top-right hand corner. You can then paste it into your RScript. Guided Example We are now going to use the WDI, and produce a crosstab of life expectancy at birth, total (years) by GDP per capita (constant 2010 US$), using the variables lifeexp and gdppc We first need to recode both variables into factor variables, as these are continuous. First up is lifeexp Recoding: as a refresher from PO11Q, we are specifying the new data frame as the old one, then we add a pipe, and call the function mutate. Therein, we create a new variable called lifecat, which will be an ordered factor, cutting the variable life at the stated intervals, and labeling these levels accordingly. library(tidyverse) wdi &lt;- wdi %&gt;% mutate(lifecat= ordered( cut(lifeexp, breaks=c(0,77,84), labels=c(&quot;low&quot;,&quot;high&quot;)))) Make a habit of adding a note underneath each code chunk in your RScript (with a ‚Äò#‚Äô) in which you translate the code into plain English. Next up is gdppc which we are recoding into a factor variable with three levels: wdi &lt;- wdi %&gt;% mutate(gdpcat= ordered( cut(gdppc, breaks=c(0,3861.5,25260, 150000), labels=c(&quot;low&quot;,&quot;medium&quot;, &quot;high&quot;)))) Let us now see whether the level of GDP has an influence on life expectancy State the null and the alternative hypothesis (directional) Run the cross-tabulation, by calling: wdi_table &lt;- with(wdi, table(gdpcat, lifecat)) wdi_table lifecat gdpcat low high low 69 0 medium 54 16 high 3 27 Now perform a chi-squared test, using the command2 Xsq &lt;- chisq.test(wdi_table, correct=FALSE) Xsq Pearson&#39;s Chi-squared test data: wdi_table X-squared = 89.702, df = 2, p-value &lt; 2.2e-16 As on PO11Q, I have prepared flashcards to help you learn R functions. These have their own section each week in this companion, but are also available on the more general POQ Flashcard Page. Are the results statistically significant? At what level? What do these results mean for our hypotheses? Produce the table of expected frequencies, using the command round(Xsq$expected, 2) lifecat gdpcat low high low 51.44 17.56 medium 52.19 17.81 high 22.37 7.63 You can compare that to the observed ones: round(Xsq$observed, 2) lifecat gdpcat low high low 69 0 medium 54 16 high 3 27 You can see that this is identical to producing the cross-tabulation in the first place: wdi_table lifecat gdpcat low high low 69 0 medium 54 16 high 3 27 In plain English: What have we found out? Exercises Let us find out whether the completion of primary school influences unemployment rates. State the null and directional alternative hypothesis for this test. Create a new variable primary_fac using the prim_compl variable. Cut it into three categories ‚Äúlow‚Äù, ‚Äúmedium‚Äù, and ‚Äúhigh‚Äù, cutting prim_compl at its first quartile, and its mean. Apply the same procedure to unemploy, creating a new variable called unemp_fac. Create a cross-tabulation assessing the dependence of unemployment on primary completion rate. unemp_fac. Test whether the dependence is statistically significant. unemp_fac. Repeat steps 1a) to 1e) for two variables of your own choice. Homework for Week 2 Read the items marked ‚Äúessential‚Äù on the reading list (see Talis) Work through this and next week‚Äôs ‚ÄúMethods, Methods, Methods‚Äù Sections. Work through this week‚Äôs flashcards to familiarise yourself with the relevant R functions. Find an example for each NEW function and apply it in R to ensure it works Complete the Week 1 Moodle Quiz Solutions You can find the Solutions in the Downloads Section. Some of the content of this worksheet is taken from Reiche (forthcoming).‚Ü©Ô∏é I am using the correct=FALSE option here to reproduce the \\(\\chi^{2}\\)-value you would get if you calculated this by hand. Technically, \\(\\chi^{2}\\) is only an approximation of the hypergeometric distribution which would deliver an exact test. You can get the precise value by applying Yates‚Äô continuity correction with correct=TRUE.‚Ü©Ô∏é "],["flashcards.html", "Flashcards", " Flashcards All R Functions on PO11Q Before embarking on PO12Q, please revise all R functions we used on PO11Q: The data are available as a .csv file. All R Functions we used this Week The data are available as a .csv file. "],["methods-methods-methods-1.html", "Methods, Methods, Methods Data Prep Video and RScript", " Methods, Methods, Methods This week‚Äôs method is the two-sample-test, for both means and proportions. Just as last week we will be working with the American National Election Studies (ANES), and to be more precise with the pilot survey conducted before the 2020 presidential election. If you haven‚Äôt already done so, you will have to register with ANES in order to download the data set. To do so, please follow this link. Data Prep Place the ANES data in a folder which you will be using as a working directory for this session. Open the ‚ÄúCode for Data Preparation‚Äù below, and copy this into an RScript. Remember to adjust the working directory with the setwd() command at the beginning. Then run the RScript and you will be ready to proceed to the video. Code for Data Preparation ###################################### # MMM - Week 2 - Data Preparation ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes.csv&quot;) # Get rid of missing values for variables used in analysis today ## 999 is equivalent to NA, so needs to be recoded anes$fttrump1 &lt;- with(anes, replace(fttrump1, fttrump1 == 999, NA)) anes$income &lt;- with(anes, replace(income, income == 99, NA)) anes &lt;- filter(anes, !is.na(fttrump1), !is.na(sex), !is.na(income)) # turn support for Trump `fttrump1` into binary variable measuring support anes &lt;- anes %&gt;% mutate(trump= cut(fttrump1, breaks=c(-1, 51, 100), labels=c(&quot;no&quot;,&quot;yes&quot;))) anes$trump &lt;- as.factor(anes$trump) # Label variable `sex` anes$sex &lt;- factor(anes$sex) anes &lt;- anes %&gt;% mutate(sex= recode(sex,&quot;1&quot;=&quot;Male&quot;, &quot;2&quot;=&quot;Female&quot;)) anes$sex &lt;- as.factor(anes$sex) # Turn income variable into a numerical variable with mid-points of each level anes$income &lt;- factor(anes$income) anes &lt;- anes %&gt;% mutate(income_fac = recode(income, &#39;1&#39;= &quot;2500&quot;, &#39;2&#39;= &quot;7499.5&quot;, &#39;3&#39;= &quot;12499.5&quot;, &#39;4&#39;= &quot;17499.5&quot;, &#39;5&#39;= &quot;22499.5&quot;, &#39;6&#39;= &quot;27499.5&quot;, &#39;7&#39;= &quot;32499.5&quot;, &#39;8&#39;= &quot;37499.5&quot;, &#39;9&#39;= &quot;42499.5&quot;, &#39;10&#39;= &quot;47499.5&quot;, &#39;11&#39;= &quot;52499.5&quot;, &#39;12&#39;= &quot;57499.5&quot;, &#39;13&#39;= &quot;62499.5&quot;, &#39;14&#39;= &quot;67499.5&quot;, &#39;15&#39;= &quot;72499.5&quot;, &#39;16&#39;= &quot;77499.5&quot;, &#39;17&#39;= &quot;82499.5&quot;, &#39;18&#39;= &quot;87499.5&quot;, &#39;19&#39;= &quot;92499.5&quot;, &#39;20&#39;= &quot;97499.5&quot;, &#39;21&#39;= &quot;112499.5&quot;, &#39;22&#39;= &quot;137499.5&quot;, &#39;23&#39;= &quot;162499.5&quot;, &#39;24&#39;= &quot;187499.5&quot;, &#39;25&#39;= &quot;224999.5&quot;, &#39;26&#39;= &quot;500000&quot;)) anes$inc &lt;- as.numeric(as.character(anes$income_fac)) # save data set for use in video write.csv(anes, &quot;anes_week2.csv&quot;) Video and RScript You can find the video introducing you to this week‚Äôs method by way of a worked example below. You can also access the code I am typing up in the video in the ‚ÄúCode for Data Analysis‚Äù section. I would encourage you to type it yourself, though, as then code tends to better sink into the depths of your brain üòâ Code for Data Analysis ###################################### # MMM - Week 2 - t-Test ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes_week2.csv&quot;) anes$sex &lt;- as.factor(anes$sex) anes$trump &lt;- as.factor(anes$trump) # tTest for a proportion ############################ # Is the proportion of men supporting Trump higher than the proportion of women? table(anes$sex, anes$trump) # are proportions equal? prop.test(c(606,682),c(1600,1469), correct=F) #is the proportion of women larger? prop.test(c(606,682),c(1600,1469), correct=F, alternative = &quot;greater&quot;) # # tTest for a mean ############################ # Do men earn more in the US than women? install.packages(&quot;car&quot;) library(car) leveneTest(anes$inc ~ anes$sex) # we reject the null, variances are not equal t.test(inc ~ sex, data=anes, var.equal = FALSE) table(anes$sex) t.test(inc ~ sex, data=anes, var.equal = FALSE, alternative = &quot;less&quot;) Two-Sample Tests in R "],["worksheet-week-2.html", "Worksheet Week 2 Self-Assessment Questions3 Two-Sample Tests in R Homework for Week 3 Solutions", " Worksheet Week 2 Self-Assessment Questions3 Give an example for a two-sample test for a mean. Give an example for a two-sample test for a proportion. Why do we calculate the t-score as \\(t =\\frac{\\text{Estimate of parameter - null hypothesis value of parameter}}{\\text{Standard error of estimate}}\\) ? What is the difference between a t-score and a z-score? What are the strengths and weaknesses of two-sample tests? Please stop here and don‚Äôt go beyond this point until we have compared notes on your answers. Two-Sample Tests in R Data Preparation We are working with the World Development Indicators again. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). To save you clicking back to last week, here is the code book (you are welcome): Table 2: WDI Codebook variable label Country Name Country Name Country Code Country Code year year democracy 0 = Autocracy, 1 = Dictatorship (Boix et al., 2018) gdppc GDP per capita (constant 2010 US$) gdpgrowth Absolute growth of per capita GDP to previous year (constant 2010 US Dollars) enrl_gross School enrollment, primary (% gross) enrl_net School enrollment, primary (% net) agri Employment in agriculture (% of total employment) (modeled ILO estimate) slums Population living in slums (% of urban population) telephone Fixed telephone subscriptions (per 100 people) internet Individuals using the Internet (% of population) tax Tax revenue (% of GDP) electricity Access to electricity (% of population) mobile Mobile cellular subscriptions (per 100 people) service Services, value added (% of GDP) oil Oil rents (% of GDP) natural Total natural resources rents (% of GDP) literacy Literacy rate, adult total (% of people ages 15 and above) prim_compl Primary completion rate, total (% of relevant age group) infant Mortality rate, infant (per 1,000 live births) hosp Hospital beds (per 1,000 people) tub Incidence of tuberculosis (per 100,000 people) health_ex Current health expenditure (% of GDP) ineq Income share held by lowest 10% unemploy Unemployment, total (% of total labor force) (modeled ILO estimate) lifeexp Life expectancy at birth, total (years) urban Urban population (% of total population) polity5 Combined Polity V score Load the data set The Polity V Score (variable polity5) codes regimes from -10 (indicating perfect autocracy) to +10 (indicating perfect democracy). With the tidyvserse, create a new variable called politybin which codes all countries with a Polity V score lower than +1 as dictatorships, and all countries with a Polity V score from +1 to +10 as democracies. Apply the same procedure to gdppc, cutting it at its median into two levels, Developing and Developed, creating a new variable called gdpcat. Last up is the variable gdpgrowth. Create a new variable called growth which divides countries into ‚Äúslow-growing‚Äù and ‚Äúfast-growing‚Äù countries, using the mean as the cut-off point. Guided Example ‚Äì Two-Sample Test for a Proportion Let us find out whether a higher proportion of developing countries is autocratic than developed countries. State the null hypothesis and the directional alternative hypothesis for this research question. In order to test this hypothesis, we need to first create a cross-tabulation: table(wdi$gdpcat, wdi$politybin) Dictatorship Democracy Developing 23 54 Developed 16 54 We now take the number of observations which are classed as dictatorships per development status. We also calculate the row totals, as this gives us the total number of developing and developed countries, respectively. Then we are ready to use the prop.test() command, by first specifying the number of countries which are dictatorships, then the total number of developing and developed countries, then advising R that a correction for small sample sizes is not necessary in our case. R uses a \\(\\chi^2\\)-test for this, as we are essentially dealing with a cross-tabulation. When you do this by hand, please use z-scores and the normal distribution. Our hypothesis is directional, because we expect a higher proportion of developing countries to be dictatorships than developed countries. The status Developing is the lower category, and we thus expect this proportion to be larger, or ‚Äúgreater‚Äù. We add this to the test function as option alternative = \"greater\". prop.test(c(23,16),c(77,70), correct=F, alternative = &quot;greater&quot;) 2-sample test for equality of proportions without continuity correction data: c(23, 16) out of c(77, 70) X-squared = 0.92517, df = 1, p-value = 0.1681 alternative hypothesis: greater 95 percent confidence interval: -0.04893134 1.00000000 sample estimates: prop 1 prop 2 0.2987013 0.2285714 Which proportion of developing and developed countries are dictatorships? Do we verify or falsify our hypothesis at a 95% confidence level? How would the R code change, if we investigated whether a higher proportion of developing countries is autocratic than developed countries? Exercise ‚Äì Two-Sample Test for a Proportion Is a higher proportion of fast-growing countries democratic than slow-growing countries? Use a 95% confidence level. Now repeat the exercise, but this time with the democracy variable. Do the results differ? Why? Why not? Calculate the last two-sample test by hand. Guided Example ‚Äì Two-Sample Test for a Mean Now we are interested whether people live longer in developed countries than in developing countries? For this, we use the variable life Once again, state the Null- and the Alternative Hypothesis The first step in a t-test for two means is to find out whether the variance is equal in both samples. Explain why this is required in a two-sample test for a mean, and why we did not have to do this in a two-sample test for a proportion. To test for equal variances we use the Levene Test, where: H\\(_{0}\\): The variance among the groups is equal. H\\(_{\\text{A}}\\): The variance among the groups is not equal. This is essentially another two-sample test in which we ascertain whether the difference between the variances of the two groups is different from zero (H\\(_{0}\\)) For the Levene test you need the car package, where ‚Äúcar‚Äù stands for ‚ÄúCompanion to Applied Regression‚Äù: install.packages(&quot;car&quot;) Now we call the package and perform the test: library(car) leveneTest(wdi$lifeexp ~ wdi$gdpcat) Levene&#39;s Test for Homogeneity of Variance (center = median) Df F value Pr(&gt;F) group 1 11.544 0.0008498 *** 167 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The result is significant, and we therefore reject the null hypothesis. This means that the variance in the two samples is not equal. Now we can perform the t-test. We once again specify alternative=\"less\" as an option, due to the same reasoning as before. t.test(lifeexp ~ gdpcat, data=wdi, var.equal = FALSE, alternative=&quot;less&quot;) Welch Two Sample t-test data: lifeexp by gdpcat t = -10.83, df = 159.03, p-value &lt; 2.2e-16 alternative hypothesis: true difference in means between group Developing and group Developed is less than 0 95 percent confidence interval: -Inf -8.477836 sample estimates: mean in group Developing mean in group Developed 66.80181 76.80833 Can we conclude at a 95% confidence level, that people live longer in developed countries than in developing countries? What is the precise p-value for the hypothesis that the true difference in means between group Developing and group Developed is greater than 0? Exercise ‚Äì Two-Sample Test for a Mean Do people live longer under democracies than under dictatorahips (use the politybin variable)? Use a 95% confidence level. Homework for Week 3 There is no separate reading for the Week 3 seminar Work through this week‚Äôs flashcards to familiarise yourself with the relevant R functions. Find an example for each NEW function and apply it in R to ensure it works Complete the Week 2 Moodle Quiz Complete Exercise 4.55 in Agresti (2018, p. 112) Work through the Section ‚ÄúIntroduction to Matrices‚Äù. Solutions You can find the Solutions in the Downloads Section. Some of the content of this worksheet is taken from Reiche (forthcoming).‚Ü©Ô∏é "],["flashcards-1.html", "Flashcards", " Flashcards New Functions This Week The data are available as a .csv file. R Functions This Week The data are available as a .csv file. All R Functions So Far The data are available as a .csv file. "],["introduction-to-matrices.html", "Introduction to Matrices What is a Matrix?4 Matrix Notation Calculating with Matrices Special Matrices", " Introduction to Matrices What is a Matrix?4 The word ‚Äúmatrix‚Äù generally conjures up levels of horror in students which even Stephen King would be struggling to match5. And I have to admit that I have not always been best friends with them myself, either. But they are useful, and in their ability to convey a large amount of information in a structured and logical way, they are even beautiful. Because at the end of the day, a matrix is nothing more than a list. In the lecture I introduced you to the concept of the Population Regression Function (PRF) which can be written as: \\[\\begin{equation} y_{i} = \\beta_{0} + \\beta_{1} x_{i} + \\epsilon_{i} \\end{equation}\\] If we wanted to write out this equation for every observation in our data set, it would look something like this: \\[\\begin{align*} y_{1} &amp;= \\beta_{0} + \\beta_{1} x_{1} + \\epsilon_{1} \\\\ y_{2} &amp;= \\beta_{0} + \\beta_{1} x_{2} + \\epsilon_{2} \\\\ &amp;\\vdots \\\\ y_{n} &amp;= \\beta_{0} + \\beta_{1} x_{n} + \\epsilon_{n} \\end{align*}\\] This is incredibly wasteful, as it unnecessarily repeats notation. What we could do instead is to create a list which has as many columns as there are unique elements in these equations (since they all have the same structure), and only note the numeric values which actually change. And there you have a matrix: Whilst this is what we will be using matrices for next week, let us leave regression aside for now, and focus on working with matrices more generally. We will now be using these two sample matrices: \\[\\begin{equation*} A = \\begin{bmatrix} 1 &amp; 7 &amp; 3\\\\ 9 &amp; 5 &amp; 4\\\\ \\end{bmatrix} \\hspace{0.75cm} B = \\begin{bmatrix} 6 &amp; 3 &amp; 8 &amp; 2 \\\\ 3 &amp; 2 &amp; 1 &amp; 4 \\\\ 1 &amp; 5 &amp; 3 &amp; 9 \\\\ \\end{bmatrix} \\end{equation*}\\] Matrix Notation We can refer to individual elements of a matrix by stating the name of the matrix, and then in the index first the row, followed by the column (you might recognise this logic from R ‚Äì this is because it is the same). With respect to matrix A, for example, the value in the first row and first column (1) would be referred to as A\\(_{11}=1\\) The number in the first row, but second column would be referred to as A\\(_{12}=7\\) What is the value of B\\(_{23}\\)? Calculating with Matrices We will only need to multiply and divide matrices on this module, so let‚Äôs cover these operations now. Multiplying Matrices To show you how this is done, I will multiply matrix A with matrix B and record the results in a new matrix called C. \\[\\begin{equation*} A \\times B = C = \\begin{bmatrix} 1 &amp; 7 &amp; 3\\\\ 9 &amp; 5 &amp; 4\\\\ \\end{bmatrix} \\times \\begin{bmatrix} 6 &amp; 3 &amp; 8 &amp; 2 \\\\ 3 &amp; 2 &amp; 1 &amp; 4 \\\\ 1 &amp; 5 &amp; 3 &amp; 9 \\\\ \\end{bmatrix} = \\begin{bmatrix} 30 &amp; 32 &amp; 24 &amp; 51\\\\ 73 &amp; 57 &amp; 89 &amp; 74\\\\ \\end{bmatrix} \\end{equation*}\\] In order to calculate a new element \\(C_{i,j}\\), we multiply the elements of the \\(i^{th}\\) row of A with the elements of the \\(j^{th}\\) column of B. We then add together these so-called inner products in order to arrive at \\(C_{i,j}\\). Let me give you some examples in which I have set the values from matrix A in bold to make the process more transparent. \\(C_{11}=\\textbf{1}\\times6+\\textbf{7}\\times3+\\textbf{3}\\times1=30\\) \\(C_{12}=\\textbf{1}\\times3+\\textbf{7}\\times2+\\textbf{3}\\times5=32\\) \\(C_{21}=\\textbf{9}\\times6+\\textbf{5}\\times3+\\textbf{4}\\times1=73\\) I have prepared a short video taking you through this process step by step. I would encourage you to watch it now. If you can‚Äôt get enough of my delightful German accent, then I have some videos for you in which I go through the respective operation with matrices on screen. Here is the first: Multiplying Matrices Assume we are multiplying a 4x3 matrix with a 3x4 matrix with one another. How many rows and columns does the resulting matrix have? Dividing Matrices In order to be able to divide by an entire matrix, we take its inverse, and then multiply with the inverse6. We do the same in the non-matrix world. For example, if we wanted to divide 6 by 3, this is the same as multiplying 6 with \\(\\frac{1}{3}\\), the inverse of 3. Sadly, inverting a matrix is not quite as straightforward as this. In fact, it is one of the most challenging operations you can do with a matrix. Luckily, the inversion of a 2 by 2 matrix (which is what we will be using) is still possible without a degree in algebra. The inverse \\(D^{-1}\\) of a 2 by 2 matrix \\(D\\) is defined as \\[\\begin{equation*} D^{-1} = \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\\\ \\end{bmatrix}^{-1} = \\frac{1}{ad-bc} \\begin{bmatrix} d &amp; -b \\\\ -c &amp; a \\\\ \\end{bmatrix}^{-1} \\end{equation*}\\] Thus, to arrive at the inverse of a 2 by 2 matrix, we first have to form the fraction in front of it. This takes as its denominator the difference between the products of the diagonal elements. We also refer to the denominator as the determinant of the matrix. In a second step ‚Äì now in the matrix itself ‚Äì we swap a and d, and set a minus sign in front of b and c. Dividing Matrices Special Matrices There are two types of matrices we will be using which hold special, useful properties. This is the transpose of a matrix, and the so-called identity matrix. Transposing Matrices Another important operation is transposing a matrix, which turns rows into columns and columns into rows. We denote a transposed matrix with an apostrophe. Transposing matrix \\(A\\) into matrix \\(A^\\prime\\) gives us: \\[\\begin{equation*} A = \\begin{bmatrix} 1 &amp; 7 &amp; 3\\\\ 9 &amp; 5 &amp; 4\\\\ \\end{bmatrix} \\hspace{0.75cm} A^\\prime = \\begin{bmatrix} 1 &amp; 9 \\\\ 7 &amp; 5 \\\\ 3 &amp; 4 \\\\ \\end{bmatrix} \\end{equation*}\\] Transposing Matrices We have the following matrix: \\[\\begin{equation*} X = \\begin{bmatrix} 2 &amp; 4 \\\\ 3 &amp; 6 \\\\ \\end{bmatrix} \\end{equation*}\\] Calculate \\(X^{\\prime}X\\). The Identity Matrix There is only one last thing left to show you before we can embark on using matrices for deriving and estimating our regression coefficients. And that is the so-called identity matrix \\(I\\). This matrix is always square, has the value 1 on all diagonal elements, and zeros otherwise. If a matrix is multiplied with \\(I\\), we receive the original matrix. For example let \\[\\begin{equation*} I = \\begin{bmatrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1\\\\ \\end{bmatrix} \\end{equation*}\\] If we multiply I with matrix B we receive \\[\\begin{equation*} I \\times B = \\begin{bmatrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1\\\\ \\end{bmatrix} \\times \\begin{bmatrix} 6 &amp; 3 &amp; 8 &amp; 2 \\\\ 3 &amp; 2 &amp; 1 &amp; 4 \\\\ 1 &amp; 5 &amp; 3 &amp; 9 \\\\ \\end{bmatrix} = \\begin{bmatrix} 6 &amp; 3 &amp; 8 &amp; 2 \\\\ 3 &amp; 2 &amp; 1 &amp; 4 \\\\ 1 &amp; 5 &amp; 3 &amp; 9 \\\\ \\end{bmatrix} \\end{equation*}\\] This feature will be important in the derivation of estimators next week, where we will make use of the fact that a matrix multiplied with its inverse results in an identity matrix. For example \\(A \\times A^{-1} = I\\). Identity Matrix This material is taken from Reiche (forthcoming).‚Ü©Ô∏é He is by far my favourite author. If you haven‚Äôt, already, read IT.‚Ü©Ô∏é This draws on https://www.mathsisfun.com/algebra/matrix-inverse.html‚Ü©Ô∏é "],["worksheet-week-3.html", "Worksheet Week 3 Self-Assessment Questions7 Regression ‚Äì Theory Calculations with Matrices Homework for Week 4", " Worksheet Week 3 Self-Assessment Questions7 Explain the difference between \\(\\hat{y}_i\\) and \\(y_i\\). Give an example for a scenario in which you could use regression analysis. Why is there an error term in regression? How does an error term differ from a residual? Explain what the conditional expectation function (CDF) means in plain English. Please stop here and don‚Äôt go beyond this point until we have compared notes on your answers. Regression ‚Äì Theory You are given the scatter plot in Figure 2.7 (taken from Gujarati &amp; Porter, 2009, p. 50) along with the regression line. What general conclusion do you draw from this diagram? Is the regression line sketched in the diagram a population regression line or a sample regression line? Calculations with Matrices We will start working with matrices next week. To familiarise yourself with these and to get a better overview how to work with them, please work through the following exercises. Feel free to consult the ‚ÄúIntroduction to Matrices‚Äù Section for this. First, answer these questions: What is a matrix? What does transposition do? What is the purpose of an identity matrix? Now, consider the following three matrices A, B, and C: \\[\\begin{equation*} A = \\begin{bmatrix} 9 &amp; 4 &amp; 11 \\\\ 6 &amp; 8 &amp; 3 \\\\ 14 &amp; 7 &amp; 9 \\\\ \\end{bmatrix} \\hspace{1cm} B = \\begin{bmatrix} 13 &amp; 8 &amp; 12 &amp; 2 \\\\ 1 &amp; 5 &amp; 15 &amp; 3 \\\\ \\end{bmatrix} \\hspace{1cm} C = \\begin{bmatrix} 25 &amp; 22 \\\\ 31 &amp; 19 \\\\ \\end{bmatrix} \\end{equation*}\\] What is the value in: \\(A_{22}\\) \\(A_{31}\\) \\(B_{13}\\) \\(B_{24}\\) \\(C_{12}\\) \\(C_{21}\\) Transpose \\(B\\) into \\(B^\\prime\\) using the following blank matrix. \\[\\begin{equation*} B^\\prime = \\begin{bmatrix} &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp;\\\\ \\end{bmatrix} \\end{equation*}\\] Solve \\(D\\) where \\(C \\times B = D\\) using the following blank matrix. \\[\\begin{equation*} D = \\begin{bmatrix} &amp; &amp; &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp; &amp; &amp;\\\\ &amp; &amp; &amp; &amp; &amp; &amp;\\\\ \\end{bmatrix} \\end{equation*}\\] Solve \\(C^{-1}\\), showing your workings using the appropriate formula. \\[\\begin{equation*} C^{-1} = \\frac{\\:}{\\hspace{2.5cm}} \\begin{bmatrix} &amp; &amp; &amp; &amp; \\\\ &amp; &amp; &amp; &amp; \\\\ \\end{bmatrix} \\hspace{2.5mm}=\\hspace{2.5mm} \\begin{bmatrix} &amp; &amp; &amp; &amp; \\\\ &amp; &amp; &amp; &amp; \\\\ \\end{bmatrix} \\end{equation*}\\] Homework for Week 4 There is no separate reading for the seminar in Week 4 Work through the Week 4 ‚ÄúMethods, Methods, Methods‚Äù Section. Work through this week‚Äôs flashcards to familiarise yourself with the relevant R functions. Find an example for each NEW function and apply it in R to ensure it works Complete the Week 3 Moodle Quiz Familiarise yourself further with matrices by setting yourself two sample matrices, A and B (each should be a 2x2 matrix). Conduct the following operations: Multiply A and B Invert A and B Transpose A and B Multiply A with an Identity Matrix Multiply A with A\\(^{-1}\\). What is the result called? You can check your solutions with https://matrixcalc.org/ . You can also try to figure out how to do this in R. This is a great way to practice working with matrices until you are familiar with the procedure. Some of the content of this worksheet is taken from Reiche (forthcoming).‚Ü©Ô∏é "],["glossary.html", "Glossary", " Glossary Table 3: Glossary Week 3 Term Description coefficient A coefficient is a numerical expression which is multiplied with the value of a variable conditional expectation function see Population Regression Function (PRF) error term The error term quantifies the distance between each observation and the corresponding point on the regression line. The terms are denoted as \\(\\epsilon_{i}\\) intercept The intercept is the point at which the regression line intersects the y-axis. In this book we denote it as \\(\\beta_{0}\\) Ordinary Least Squares The method of fitting a regression line by means of minimizing the sum of the squared distances between the observations and the estimated values Population Regression Function The Population Regression Function (PRF) describes the expected distribution of \\(y\\), given the values of the independent variable(s) \\(x\\). It is also called the conditional expectation function (CEF) and can be denoted as \\(E(y_{i}|x_{i})\\) regression Regression analysis determines the direction and magnitude of influence of one or more independent variables on a dependent variable regression line The regression line describes how the dependent variable is functionally related to the values of the independent variable. It it defined by the intercept \\(\\beta_{0}\\) and the slope \\(\\beta_{1}\\) residual An estimation of the error term. The difference between an observation \\(y_{i}\\) and the estimated value \\(\\hat{y}_{i}\\). Denoted as \\(\\hat{\\epsilon}_{i}\\) Sample Regression Function A regression line based on a randomly drawn sample slope A slope is defined as rise over run, and so it tells us how many units of y we need to climb (or descend if the slope is negative) for every additional unit of the independent variable \\(x\\) "],["flashcards-2.html", "Flashcards", " Flashcards New Functions This Week The data are available as a .csv file. R Functions This Week The data are available as a .csv file. All R Functions So Far The data are available as a .csv file. "],["methods-methods-methods-2.html", "Methods, Methods, Methods Data Prep Video and RScript", " Methods, Methods, Methods This week we will be starting to conduct linear regression analysis in R. Just as in week 2 we will be working with the American National Election Studies (ANES), and to be more precise with the pilot survey conducted before the 2020 presidential election. If you haven‚Äôt already done so, you will have to register with ANES in order to download the data set. To do so, please follow this link. Data Prep Place the ANES data in a folder which you will be using as a working directory for this session. Open the ‚ÄúCode for Data Preparation‚Äù below, and copy this into an RScript. Remember to adjust the working directory with the setwd() command at the beginning. Then run the RScript and you will be ready to proceed to the video. Code for Data Preparation ###################################### # MMM - Week 4 - Data Preparation ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes.csv&quot;) # Get rid of missing values for variables used in analysis today ## 999 is equivalent to NA, so needs to be recoded anes$fttrump1 &lt;- with(anes, replace(fttrump1, fttrump1 == 999, NA)) anes$income &lt;- with(anes, replace(income, income == 99, NA)) anes &lt;- filter(anes, !is.na(fttrump1), !is.na(age), !is.na(income)) # Turn income variable into a numerical variable with mid-points of each level anes$income &lt;- factor(anes$income) table(anes$income) anes &lt;- anes %&gt;% mutate(income_fac = recode(income, &#39;1&#39;= &quot;2500&quot;, &#39;2&#39;= &quot;7499.5&quot;, &#39;3&#39;= &quot;12499.5&quot;, &#39;4&#39;= &quot;17499.5&quot;, &#39;5&#39;= &quot;22499.5&quot;, &#39;6&#39;= &quot;27499.5&quot;, &#39;7&#39;= &quot;32499.5&quot;, &#39;8&#39;= &quot;37499.5&quot;, &#39;9&#39;= &quot;42499.5&quot;, &#39;10&#39;= &quot;47499.5&quot;, &#39;11&#39;= &quot;52499.5&quot;, &#39;12&#39;= &quot;57499.5&quot;, &#39;13&#39;= &quot;62499.5&quot;, &#39;14&#39;= &quot;67499.5&quot;, &#39;15&#39;= &quot;72499.5&quot;, &#39;16&#39;= &quot;77499.5&quot;, &#39;17&#39;= &quot;82499.5&quot;, &#39;18&#39;= &quot;87499.5&quot;, &#39;19&#39;= &quot;92499.5&quot;, &#39;20&#39;= &quot;97499.5&quot;, &#39;21&#39;= &quot;112499.5&quot;, &#39;22&#39;= &quot;137499.5&quot;, &#39;23&#39;= &quot;162499.5&quot;, &#39;24&#39;= &quot;187499.5&quot;, &#39;25&#39;= &quot;224999.5&quot;, &#39;26&#39;= &quot;500000&quot;)) anes$inc &lt;- as.numeric(as.character(anes$income_fac)) # save data set for use in video write.csv(anes, &quot;anes_week4.csv&quot;) Video and RScript You can find the video introducing you to this week‚Äôs method by way of a worked example below. You can also access the code I am typing up in the video in the ‚ÄúCode for Data Analysis‚Äù section. I would encourage you to type it yourself, though, as then code tends to better sink into the depths of your brain üòâ Code for Data Analysis ###################################### # MMM - Week 4 - Bivariate Regression ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes_week4.csv&quot;) # Visualisation ############################ ggplot(anes, aes(x = inc, y = fttrump1)) + geom_point() + geom_smooth(method = lm) # Regression ############################ model1 &lt;- lm(fttrump1 ~ inc, data = anes) model1 Bivariate Regression in R "],["worksheet-week-4.html", "Worksheet Week 4 Self-Assessment Questions8 Regression ‚Äì Calculations Regression in R Homework for Week 5 Solutions", " Worksheet Week 4 Self-Assessment Questions8 How does OLS fit the regression line? Why do we have to square the residuals for the method of OLS? Explain the concept of an identity matrix. Consider the vector of error terms \\(\\epsilon\\) (an n \\(\\times\\) 1 matrix). How do you write \\(\\sum \\epsilon^2\\) in matrix notation? Please stop here and don‚Äôt go beyond this point until we have compared notes on your answers. Regression ‚Äì Calculations Consider the following data set: Table 4: Regression Data Set i age (x) income (y) 1 22 700 2 19 650 3 56 2300 4 45 1900 5 37 2000 6 23 900 7 32 1000 8 65 2500 9 43 1800 10 48 1200 Plot the data in Table 4 in a suitable scatter plot. Yes, on paper. Fit a line of best fit through the scatter plot (by eyeballing and a ruler). Assuming a regression model of the type \\(Y_{i}=\\beta_{0}+ \\beta_{1}X_{i}+\\epsilon_{i}\\), calculate the estimators for \\(\\beta_{0}\\) and \\(\\beta_{1}\\). Create a table like the one I used in the lecture. How do do the intermediary calculations in this table relate to the formulae for the coefficients? Calculate the regression coefficients \\(\\hat{\\beta}_{0}\\) and \\(\\hat{\\beta}_{1}\\) using matrices. Specify the SRF and interpret the estimators of \\(\\beta_{0}\\) and \\(\\beta_{1}\\). Regression in R Load the income data set PO12Q_4.xlsx library(readxl) incomedata &lt;- read_excel(&quot;PO12Q_4.xlsx&quot;) You can also enter the values of a table manually using the matrix() function as follows: table &lt;- matrix(c(22,19,56,45,37,23,32,65,43,48, 700,650,2300,1900,2000,900,1000,2500,2800,1200), nrow=10,ncol=2) incomedata &lt;- data.frame(table) Run the regression in R as follows: regression &lt;- lm(income ~ age, data = incomedata) summary(regression) Call: lm(formula = income ~ age, data = incomedata) Residuals: Min 1Q Median 3Q Max -652.25 -102.92 6.53 142.21 584.39 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -53.092 304.716 -0.174 0.866011 age 39.695 7.325 5.419 0.000631 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 335.3 on 8 degrees of freedom Multiple R-squared: 0.7859, Adjusted R-squared: 0.7592 F-statistic: 29.37 on 1 and 8 DF, p-value: 0.0006314 Check your results from the first section. Homework for Week 5 Read the items marked ‚Äúessential‚Äù on the reading list (see Talis) Work through this week‚Äôs flashcards to familiarise yourself with the relevant R functions. Find an example for each NEW function and apply it in R to ensure it works Complete the Week 4 Moodle Quiz Work through the Week 5 ‚ÄúMethods, Methods, Methods‚Äù Section. Solutions You can find the Solutions in the Downloads Section. Make up a data set like the one in this worksheet and practice calculations. You can check your results either with R, or with the Excel sheet in the solutions if you want the intermidiary results. Some of the content of this worksheet is taken from Reiche (forthcoming).‚Ü©Ô∏é "],["glossary-1.html", "Glossary", " Glossary Table 5: Glossary Week 4 Term Description matrix A ‚Äúset of numbers arranged in rows and columns so as to form a rectangular array‚Äù (Ronan, 2023) "],["flashcards-3.html", "Flashcards", " Flashcards New Functions This Week No new functions this week! R Functions This Week The data are available as a .csv file. All R Functions So Far The data are available as a .csv file. "],["methods-methods-methods-3.html", "Methods, Methods, Methods Data Prep Video and RScript", " Methods, Methods, Methods This week we will explore a measure for model fit, the so-called R-Squared. Discover how to obtain it in R in this section. Just as in week 4 we will be working with the American National Election Studies (ANES), and to be more precise with the pilot survey conducted before the 2020 presidential election. If you haven‚Äôt already done so, you will have to register with ANES in order to download the data set. To do so, please follow this link. Data Prep Place the ANES data in a folder which you will be using as a working directory for this session. Open the ‚ÄúCode for Data Preparation‚Äù below, and copy this into an RScript. Remember to adjust the working directory with the setwd() command at the beginning. Then run the RScript and you will be ready to proceed to the video. Code for Data Preparation ###################################### # MMM - Week 5 - Data Preparation ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes.csv&quot;) # Get rid of missing values for variables used in analysis today ## 999 is equivalent to NA, so needs to be recoded anes$fttrump1 &lt;- with(anes, replace(fttrump1, fttrump1 == 999, NA)) anes$income &lt;- with(anes, replace(income, income == 99, NA)) anes &lt;- filter(anes, !is.na(fttrump1), !is.na(age), !is.na(income)) # Turn income variable into a numerical variable with mid-points of each level anes$income &lt;- factor(anes$income) table(anes$income) anes &lt;- anes %&gt;% mutate(income_fac = recode(income, &#39;1&#39;= &quot;2500&quot;, &#39;2&#39;= &quot;7499.5&quot;, &#39;3&#39;= &quot;12499.5&quot;, &#39;4&#39;= &quot;17499.5&quot;, &#39;5&#39;= &quot;22499.5&quot;, &#39;6&#39;= &quot;27499.5&quot;, &#39;7&#39;= &quot;32499.5&quot;, &#39;8&#39;= &quot;37499.5&quot;, &#39;9&#39;= &quot;42499.5&quot;, &#39;10&#39;= &quot;47499.5&quot;, &#39;11&#39;= &quot;52499.5&quot;, &#39;12&#39;= &quot;57499.5&quot;, &#39;13&#39;= &quot;62499.5&quot;, &#39;14&#39;= &quot;67499.5&quot;, &#39;15&#39;= &quot;72499.5&quot;, &#39;16&#39;= &quot;77499.5&quot;, &#39;17&#39;= &quot;82499.5&quot;, &#39;18&#39;= &quot;87499.5&quot;, &#39;19&#39;= &quot;92499.5&quot;, &#39;20&#39;= &quot;97499.5&quot;, &#39;21&#39;= &quot;112499.5&quot;, &#39;22&#39;= &quot;137499.5&quot;, &#39;23&#39;= &quot;162499.5&quot;, &#39;24&#39;= &quot;187499.5&quot;, &#39;25&#39;= &quot;224999.5&quot;, &#39;26&#39;= &quot;500000&quot;)) anes$inc &lt;- as.numeric(as.character(anes$income_fac)) # save data set for use in video write.csv(anes, &quot;anes_week5.csv&quot;) Video and RScript You can find the video introducing you to this week‚Äôs method by way of a worked example below. You can also access the code I am typing up in the video in the ‚ÄúCode for Data Analysis‚Äù section. I would encourage you to type it yourself, though, as then code tends to better sink into the depths of your brain üòâ Code for Data Analysis ###################################### # MMM - Week 5 - Model Fit ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes_week5.csv&quot;) # Visualisation ############################ ggplot(anes, aes(x = inc, y = fttrump1)) + geom_point() + geom_smooth(method = lm) # Regression ############################ model1 &lt;- lm(fttrump1 ~ inc, data = anes) model1 summary(model1) Model Fit for Regression in R "],["worksheet-week-5.html", "Worksheet Week 5 Self-Assessment Questions9 Mathematical Properties of OLS Goodness of Fit ‚Äì Using R Goodness of Fit ‚Äì By Hand Homework for Week 7 Solutions", " Worksheet Week 5 Self-Assessment Questions9 Why do we need a measure to assess goodness of fit? How do you interpret R-Squared? Explain in your own words what the residual sum of squares (RSS) means. Explain one of the mathematical properties of OLS in your own words. Please stop here and don‚Äôt go beyond this point until we have compared notes on your answers. Mathematical Properties of OLS I showed in the lecture that the predicted values of y are uncorrelated with the residuals. Show mathematically that this is not the case for the error terms. Hint: Consider carefully Equation 2 on Slide 7. Goodness of Fit ‚Äì Using R We will be using our WDI example again to explore model fit in R. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). Download the WDI_PO12Q.csv data set. Set your working directory and load the data set as an object called wdi. We will re-assess our question from Week 1, whether the level of GDP has an influence on life expectancy State the null and the alternative hypothesis (directional) Run the regression model. wdi &lt;- read.csv(&quot;files/Week 5/WDI_PO12Q.csv&quot;) attach(wdi) model &lt;- lm(lifeexp ~ gdppc) summary(model) Call: lm(formula = lifeexp ~ gdppc) Residuals: Min 1Q Median 3Q Max -17.445 -3.260 1.545 4.760 8.969 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.815e+01 5.797e-01 117.56 &lt;2e-16 *** gdppc 2.619e-04 2.515e-05 10.41 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 6.129 on 167 degrees of freedom (26 observations deleted due to missingness) Multiple R-squared: 0.3936, Adjusted R-squared: 0.39 F-statistic: 108.4 on 1 and 167 DF, p-value: &lt; 2.2e-16 Build the SRF and interpret the coefficients. Assess and interpret model fit, using ‚ÄúMultiple R-squared‚Äù which is equivalent to the R\\(^2\\) we discussed in the lecture. We have ‚Äúonly‚Äù covered the Estimate column in this output so far. We will be working towards interpreting the rest over the next few weeks. You can also extract specific blocks of the output table by placing brackets [] after the summary() function. For example summary()[1]. Try to extract the block containing model fit, like this: $r.squared [1] 0.3936356 Goodness of Fit ‚Äì By Hand Using the data and calculations presented in the Table below, calculate the coefficient of determination, \\(r^{2}\\), with \\(\\hat{Y_{i}}= -53.1 + 39.7 X_{i}\\) Table 6: Regression Data Set i age (x) income (y) \\(y-\\bar{y}\\) \\((y-\\bar{y})^2\\) 1 22 700 700 490000 2 19 650 650 422500 3 56 2300 2300 5290000 4 45 1900 1900 3610000 5 37 2000 2000 4000000 6 23 900 900 810000 7 32 1000 1000 1000000 8 65 2500 2500 6250000 9 43 1800 1800 3240000 10 48 1200 1200 1440000 Homework for Week 7 Prepare for the in-class test in Week 7, see the Reading Week Section. Read the items marked ‚Äúessential‚Äù on the reading list (see Talis) Work through this week‚Äôs flashcards to familiarise yourself with the relevant R functions. Find an example for each NEW function and apply it in R to ensure it works Complete the Week 5 Moodle Quiz Work through the Week 7 ‚ÄúMethods, Methods, Methods‚Äù Section Solutions You can find the Solutions in the Downloads Section. Some of the content of this worksheet is taken from Reiche (forthcoming).‚Ü©Ô∏é "],["glossary-2.html", "Glossary", " Glossary Table 7: Glossary Week 5 Term Description correlation The statistical dependence of two random variables which is determined by pairwise comparison of values coefficient of determination Indicates the proportion of the variation in the dependent variable which is explained through the independent variable. It is defined as \\(\\frac{\\text{Explained Sum of Squares}}{\\text{Total Sum of Squares}}\\) "],["flashcards-4.html", "Flashcards", " Flashcards New Functions This Week The data are available as a .csv file. R Functions This Week The data are available as a .csv file. All R Functions So Far The data are available as a .csv file. "],["reading-week.html", "Reading Week Flashcards", " Reading Week You know the drill. Reading week is not an institutionalised holiday, but I do expect you to put in about 10 hours of work for this module over the course of this week. Here are a few suggestions for activities to fill these 10 hours: Catch up on the reading Revise the material of Weeks 1-5 in preparation for the in-class test in Week 7. Go through the worksheets of Weeks 1-5 for the same reason. If you struggle with understanding the code, go through the worksheets and verbalise in plain English each code chunk. If you need help with what each of the functions means then you can find descriptions in the csv files that underpin the flashcards. These are available here. Revise all R functions up to this point. I have made a special flashcard section below for this. Flashcards Reading Week Consolidation The data are available as a .csv file. "],["methods-methods-methods-4.html", "Methods, Methods, Methods Data Prep Video and RScript", " Methods, Methods, Methods This week we will delve a little deeper into the output for linear regression analysis in R to ascertain whether our coefficients are actually statistically different from zero, or put less technically whether they have an influence. Just as last week we will be working with the American National Election Studies (ANES), and to be more precise with the pilot survey conducted before the 2020 presidential election. If you haven‚Äôt already done so, you will have to register with ANES in order to download the data set. To do so, please follow this link. Data Prep Place the ANES data in a folder which you will be using as a working directory for this session. Open the ‚ÄúCode for Data Preparation‚Äù below, and copy this into an RScript. Remember to adjust the working directory with the setwd() command at the beginning. Then run the RScript and you will be ready to proceed to the video. Code for Data Preparation ###################################### # MMM - Week 7 - Data Preparation ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes.csv&quot;) # Get rid of missing values for variables used in analysis today ## 999 is equivalent to NA, so needs to be recoded anes$fttrump1 &lt;- with(anes, replace(fttrump1, fttrump1 == 999, NA)) anes$income &lt;- with(anes, replace(income, income == 99, NA)) anes &lt;- filter(anes, !is.na(fttrump1), !is.na(age), !is.na(income)) # Turn income variable into a numerical variable with mid-points of each level anes$income &lt;- factor(anes$income) table(anes$income) anes &lt;- anes %&gt;% mutate(income_fac = recode(income, &#39;1&#39;= &quot;2500&quot;, &#39;2&#39;= &quot;7499.5&quot;, &#39;3&#39;= &quot;12499.5&quot;, &#39;4&#39;= &quot;17499.5&quot;, &#39;5&#39;= &quot;22499.5&quot;, &#39;6&#39;= &quot;27499.5&quot;, &#39;7&#39;= &quot;32499.5&quot;, &#39;8&#39;= &quot;37499.5&quot;, &#39;9&#39;= &quot;42499.5&quot;, &#39;10&#39;= &quot;47499.5&quot;, &#39;11&#39;= &quot;52499.5&quot;, &#39;12&#39;= &quot;57499.5&quot;, &#39;13&#39;= &quot;62499.5&quot;, &#39;14&#39;= &quot;67499.5&quot;, &#39;15&#39;= &quot;72499.5&quot;, &#39;16&#39;= &quot;77499.5&quot;, &#39;17&#39;= &quot;82499.5&quot;, &#39;18&#39;= &quot;87499.5&quot;, &#39;19&#39;= &quot;92499.5&quot;, &#39;20&#39;= &quot;97499.5&quot;, &#39;21&#39;= &quot;112499.5&quot;, &#39;22&#39;= &quot;137499.5&quot;, &#39;23&#39;= &quot;162499.5&quot;, &#39;24&#39;= &quot;187499.5&quot;, &#39;25&#39;= &quot;224999.5&quot;, &#39;26&#39;= &quot;500000&quot;)) anes$inc &lt;- as.numeric(as.character(anes$income_fac)) # save data set for use in video write.csv(anes, &quot;anes_week7.csv&quot;) Video and RScript You can find the video introducing you to this week‚Äôs method by way of a worked example below. You can also access the code I am typing up in the video in the ‚ÄúCode for Data Analysis‚Äù section. I would encourage you to type it yourself, though, as then code tends to better sink into the depths of your brain üòâ Code for Data Analysis ###################################### # MMM - Week 7 - Hypothesis Testing ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes_week8.csv&quot;) # Visualisation ############################ ggplot(anes, aes(x = inc, y = fttrump1)) + geom_point() + geom_smooth(method = lm) # Regression ############################ model1 &lt;- lm(fttrump1 ~ inc, data = anes) model1 summary(model1) Significance Test for Coefficients in R "],["worksheet-week-7.html", "Worksheet Week 7 Self-Assessment Questions10 Regression ‚Äì Standard Errors of Coefficients Regression ‚Äì Hypothesis Testing &amp; Confidence Intervals Solutions", " Worksheet Week 7 Self-Assessment Questions10 Why does \\(\\hat{\\beta}_1\\) have a sampling distribution? What is the difference between \\(\\text{se}(\\hat{\\beta}_1)\\) and \\(\\hat{\\text{se}}(\\hat{\\beta}_1)\\)? What does \\(\\sigma^2\\) represent substantively? If \\(\\hat{\\beta}_1=0\\), why is \\(\\hat{\\beta}_0=\\bar{y}\\)? Give two reasons. Please stop here and don‚Äôt go beyond this point until we have compared notes on your answers. Regression ‚Äì Standard Errors of Coefficients Using the following regression calculations, determine the size of the standard errors of \\(\\hat{\\beta}_{0}\\) and \\(\\hat{\\beta}_{1}\\) in tabular form in matrix form Table 8: Regression Data Set i age (x) income (y) \\(y-\\bar{y}\\) \\((y-\\bar{y})^2\\) \\(x-\\bar{x}\\) \\((x-\\bar{x})^2\\) \\((x-\\bar{x})(y-\\bar{y})\\) \\(\\hat{y}\\) 1 22 700 -795 632025 -17 289 13515 820.3 2 19 650 -845 714025 -20 400 16900 701.2 3 56 2300 805 648025 17 289 13685 2170.1 4 45 1900 405 164025 6 36 2430 1733.4 5 37 2000 505 255025 -2 4 -1010 1415.8 6 23 900 -595 354025 -16 256 9520 860.0 7 32 1000 -495 245025 -7 49 3465 1217.3 8 65 2500 1005 1010025 26 676 26130 2527.4 9 43 1800 305 93025 4 16 1220 1654.0 10 48 1200 -295 87025 9 81 -2655 1852.5 MEAN 39 1495 SUM 4202250 2096 83200 Regression ‚Äì Hypothesis Testing &amp; Confidence Intervals Consider the following regression, where gdp indicates Gross Domestic Product (PPP) in 2005 US Dollars, and life indicates life expectancy at birth in years. I am running the regression with the first line and store the results in the object wdi. The second line asks R to display the detailed results for the regression. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). model1 &lt;- lm(gdppc ~ lifeexp, data = wdi) summary(model1) Call: lm(formula = gdppc ~ lifeexp, data = wdi) Residuals: Min 1Q Median 3Q Max -18457 -9877 -4187 4963 78242 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -94306.8 10406.7 -9.062 3.33e-16 *** lifeexp 1503.2 144.4 10.412 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 14690 on 167 degrees of freedom (26 observations deleted due to missingness) Multiple R-squared: 0.3936, Adjusted R-squared: 0.39 F-statistic: 108.4 on 1 and 167 DF, p-value: &lt; 2.2e-16 Formulate the null and alternative hypotheses which is tested in this model. Build the regression function. Are the coefficients significant? Interpret the coefficients. How would you interpret the coefficient if it was insignificant? Think carefully about what an insignificant result means in plain English to answer this question. Plot the regression function in a suitable diagram using ggplot. Explain how the t-value for life is obtained. What do our results mean for the hypotheses? What does the value of ‚ÄúMultiple R-Squared‚Äù (this is equivalent to the R-Squared we calculated by hand last week) mean? Calculate the 95% confidence intervals for the coefficient life and the intercept. Compare your results to the R output below. Find two explanations in the output for why the coefficient for life is statistically significant at the 5% level? confint(model1,level = 0.95) 2.5 % 97.5 % (Intercept) -114852.512 -73761.11 lifeexp 1218.183 1788.24 Solutions You can find the Solutions in the Downloads Section. Some of the content of this worksheet is taken from Reiche (forthcoming).‚Ü©Ô∏é "],["additional-exercises.html", "Additional Exercises Load Packages and data11 Inspect your data Preliminary Analysis Visualisation Visualisation 2.0 Saving the Scatterplot Regression Analysis (yes, finally) Interpretation Exporting the Results Comparing models Homework for Week 8 Solutions", " Additional Exercises Load Packages and data11 Before starting, we need to load libraries and install packages if not already installed. In these exercises we will be using the following packages: haven ggplot2 stargazer Set working directory and load the data file simd.csv into R. This is the ‚ÄúScottish Index of Multiple Deprivation‚Äù. Here is the codebook: Table 9: Codebook for simd Data Set Variable Label Data_Zone 2011 Data Zone Intermediate_Zone 2011 Intermediate Zone name Council_area Council area name Total_population 2017 NRS small area population estimates Working_age_population 2017 NRS small area population estimates and state pension age Income_rate Percentage of people who are income deprived Income_count Number of people who are income deprived Employment_rate Percentage of people who are employment deprived Employment_count Number of people who are employment deprived CIF Comparative Illness Factor: standardised ratio ALCOHOL Hospital stays related to alcohol use: standardised ratio DRUG Hospital stays related to drug use: standardised ratio mortality Standardised mortality ratio DEPRESS Proportion of population being prescribed drugs for anxiety, depression or psychosis LBWT Proportion of live singleton births of low birth weight EMERG Emergency stays in hospital: standardised ratio Attendance School pupil attendance Attainment Attainment of school leavers no_qualifications Working age people with no qualifications: standardised ratio not_participating Proportion of people aged 16-19 not participating in education, employment or training University Proportion of 17-21 year olds entering university drive_petrol Average drive time to a petrol station in minutes drive_GP Average drive time to a GP surgery in minutes drive_PO Average drive time to a post office in minutes drive_primary Average drive time to a primary school in minutes drive_retail Average drive time to a retail centre in minutes drive_secondary Average drive time to a secondary school in minutes PT_GP Public transport travel time to a GP surgery in minutes PT_Post Public transport travel time to a post office in minutes PT_retail Public transport travel time to a retail centre in minutes broadband Percentage of premises without access to superfast broadband (at least 30Mb/s download speed) crime_count Number of recorded crimes of violence, sexual offences, domestic housebreaking, vandalism, drugs offences, and common assault crime_rate Recorded crimes of violence, sexual offences, domestic housebreaking, vandalism, drugs offences, and common assault per 10,000 people overcrowded_count Number of people in households that are overcrowded nocentralheat_count Number of people in households without central heating overcrowded_rate Percentage of people in households that are overcrowded nocentralheat_rate Percentage of people in households without central heating sim_rank Rank of data zones from most deprived (ranked 1) to least deprived (ranked 6,976) Inspect your data Here you can use several basic functions. The dataset does not contain too many variables, so you can start by using names(), str(), dim(), etc. The function dim() is new. What does it do? Preliminary Analysis Now that you have a preliminary idea of the structure of the dataset, you can select two variables and test a possible relationship. Remember that the outcome variable needs to be continuous. Let‚Äôs say we want to look at the relationship between alcohol consumption and mortality rate (yes, not a very funny topic, but interesting nonetheless). The two variables are, respectively, ALCOHOL and SMR. Now, formulate the working (alternative) and the null hypothesis. H\\(\\pmb{_0}\\): H\\(\\pmb{_1}\\): Which is your dependent variable? Run a frequency table on the mortality variable. What is the level of measurement? Do the same for the other variable. And guess what is the level of measurement. Visualisation Let‚Äôs start with the visualisation of the relationship between the two variables. Use a scatterplot to visualise the relationship and add the regression line. You can use ggplot, but also the standard plot() function. Improve the initial graph by: Adding a regression line. Adding up a relevant title, also possibly a subtitle. Adding axes labels and making them readable. Removing the grid in the background. The result should be Figure 1. Figure 1: Improved Graph If you have done everything correctly, you should see that the dots are rather concentrated in the bottom left corner of the scatterplot with some outliers far away from the cloud of our data. It is not a big deal, but we might want to get rid of the outliers and this way improve our visualisation. There are several ways to do that, of course. But let‚Äôs say we want to transform our variables, excluding all values over a certain point. For example, we want to exclude the values above 750 of our alcohol variable and above 500 for our mortality variable. There are ‚Äì of course ‚Äì several solutions. One could be, to create a new datset, subsetting the original. Another solution could be to create a new variable telling R to transform all the values above our treshold in NA. Try to find an apply the appropriate code. Use Google if necessary, it helps a lot. Visualisation 2.0 Now, visualise the relationship using the reduced data frame. What can you see? You can improve the scatterplot using a series of arguments (e.g., alpha) in the geom_point() function in ggplot. Try to improve the Aesthetics of the scatterplot playing with alpha, for instance. (see R Documentation). Also, you can draw a vertical and horizontal line corresponding to the mean of your variables using geom_hline and geom_vline. You can thus check if the regression line passes through the mean of X and Y. (see R Documentation). Remember that Google and ChatGPT are your best friends when you learn to code. And after that as well - just not in exams. No one actually remembers all the functions and all their argument. The secret is to know how to google the things you need. Saving the Scatterplot You can also save a graph as .png, .JPG (even .pdf) that you can then import in a word document. Although there are many way to use your R output, saving a graph might be sometimes useful. Use the function ggsave() to save your scatterplot. Again, there are tons of examples online, google it. You first need to store the graph in an object. Regression Analysis (yes, finally) Now we can finally run a linear regression with mortality as the outcome variable and alcohol as the predictor using the lm() function. Store the results in an object called model and visualise the regression output using summary(). Use the reduced data set without outliers. Call: lm(formula = SMR ~ ALCOHOL, data = simred) Residuals: Min 1Q Median 3Q Max -146.54 -22.63 -4.72 16.73 387.27 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 76.733653 0.636021 120.65 &lt;2e-16 *** ALCOHOL 0.217635 0.004579 47.53 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 36.13 on 6959 degrees of freedom Multiple R-squared: 0.2451, Adjusted R-squared: 0.2449 F-statistic: 2259 on 1 and 6959 DF, p-value: &lt; 2.2e-16 You can also extract specific blocks of the output table. One way of doing it is to use the brackets [] after the summary() function. For example summary()[8]. Try to extract the block of Coefficients from the table, like this: $coefficients Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 76.7336534 0.636021422 120.6463 0 ALCOHOL 0.2176351 0.004579103 47.5279 0 As you go through the different numbers, take note which component of the regression output is associated with which number. Interpretation Interpret the results, starting with model evaluation. How much variation in the outcome variable does the model explain? What does this tell us about the model? Interpret the slope coefficient. Interpret the intercept? What does it mean in practice? Interpret the results (in plain language) referring to the hypothesis you formulated above. What is the answer to our research question? Exporting the Results Just as with graphs, you can also export and save the results of the regression model in a Word table. To do that you can use the stargazer package. Try to export the table. The stargazer function needs to contain, in order: the name of the R object where you stored the regression results, the option header=F to suppress the annoying immortalisation of the author, the option type=\"html\", and the option out=\"documentname.doc\" which places a word document with that file name in your working directory. Should you use MS Word to write your essay and your essay is saved in your working directory, do not save the table document under the same name as your essay, as R will overwrite it and it will be gone forever. You can improve the table in many ways. For example, you need to replace the variable names with the variable labels. You could also add a name of the model, and suppress unneeded statistics. If you have done everything correctly, you should receive something similar to this: ¬† ¬† Table 10: Impact of Alcohol Abuse on Mortality in Scotland Dependent variable: Standardised Mortality Ratio Hospital Stays related to Alcohol Use 0.218*** (0.005) Constant 76.734*** (0.636) Observations 6,961 R2 0.245 Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 ¬† ¬† Comparing models You can now run another regression model with a different independent variable. Can you compare your original model with the new one? How? How do you know which independent variable is doing a better job in explaining your dependent variable? Homework for Week 8 Read the items marked ‚Äúessential‚Äù on the reading list (see Talis) Work through this week‚Äôs flashcards to familiarise yourself with the relevant R functions. Find an example for each NEW function and apply it in R to ensure it works Complete the Week 7 Moodle Quiz Work through the Week 8 ‚ÄúMethods, Methods, Methods‚Äù Section. Solutions You can find the Solutions in the Downloads Section. These exercises were originally written by Oleksiy Bondarenko who taught the module in 2022/23. I have slightly altered them in subsequent years.‚Ü©Ô∏é "],["glossary-3.html", "Glossary", " Glossary Table 11: Glossary Week 7 Term Description confidence interval A confidence interval constructs an interval of numbers which will contain the true parameter of the population (e.g.¬†the mean) in \\((1-\\alpha)\\) times of cases. \\(\\alpha\\) is usually chosen to be small, so that our confidence interval has a probability of 95% or 99% confidence level The confidence level is the probability with which the confidence interval is believed to contain the true parameter of the population and is defined as \\((1-\\alpha)\\) degrees of freedom Degrees of freedom express constraints on our estimation process by specifying how many values in the calculation are free to vary significance level Is denoted as \\(\\alpha\\) and defined as \\(1-\\)confidence level. "],["flashcards-6.html", "Flashcards", " Flashcards New Functions This Week The data are available as a .csv file. R Functions This Week The data are available as a .csv file. All R Functions So Far The data are available as a .csv file. "],["methods-methods-methods-5.html", "Methods, Methods, Methods Data Prep Video and RScript", " Methods, Methods, Methods This week we are extending our bivariate regression model to approximate the real world in which nothing is mono-causal. We call this multiple regression. Just as last week we will be working with the American National Election Studies (ANES), and to be more precise with the pilot survey conducted before the 2020 presidential election. If you haven‚Äôt already done so, you will have to register with ANES in order to download the data set. To do so, please follow this link. Data Prep Place the ANES data in a folder which you will be using as a working directory for this session. Open the ‚ÄúCode for Data Preparation‚Äù below, and copy this into an RScript. Remember to adjust the working directory with the setwd() command at the beginning. Then run the RScript and you will be ready to proceed to the video. Code for Data Preparation ###################################### # MMM - Week 8 - Data Preparation ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes.csv&quot;) # Get rid of missing values for variables used in analysis today ## 999 is equivalent to NA, so needs to be recoded anes$fttrump1 &lt;- with(anes, replace(fttrump1, fttrump1 == 999, NA)) anes$income &lt;- with(anes, replace(income, income == 99, NA)) anes &lt;- filter(anes, !is.na(fttrump1), !is.na(age), !is.na(income)) # Turn income variable into a numerical variable with mid-points of each level anes$income &lt;- factor(anes$income) table(anes$income) anes &lt;- anes %&gt;% mutate(income_fac = recode(income, &#39;1&#39;= &quot;2500&quot;, &#39;2&#39;= &quot;7499.5&quot;, &#39;3&#39;= &quot;12499.5&quot;, &#39;4&#39;= &quot;17499.5&quot;, &#39;5&#39;= &quot;22499.5&quot;, &#39;6&#39;= &quot;27499.5&quot;, &#39;7&#39;= &quot;32499.5&quot;, &#39;8&#39;= &quot;37499.5&quot;, &#39;9&#39;= &quot;42499.5&quot;, &#39;10&#39;= &quot;47499.5&quot;, &#39;11&#39;= &quot;52499.5&quot;, &#39;12&#39;= &quot;57499.5&quot;, &#39;13&#39;= &quot;62499.5&quot;, &#39;14&#39;= &quot;67499.5&quot;, &#39;15&#39;= &quot;72499.5&quot;, &#39;16&#39;= &quot;77499.5&quot;, &#39;17&#39;= &quot;82499.5&quot;, &#39;18&#39;= &quot;87499.5&quot;, &#39;19&#39;= &quot;92499.5&quot;, &#39;20&#39;= &quot;97499.5&quot;, &#39;21&#39;= &quot;112499.5&quot;, &#39;22&#39;= &quot;137499.5&quot;, &#39;23&#39;= &quot;162499.5&quot;, &#39;24&#39;= &quot;187499.5&quot;, &#39;25&#39;= &quot;224999.5&quot;, &#39;26&#39;= &quot;500000&quot;)) anes$inc &lt;- as.numeric(as.character(anes$income_fac)) # save data set for use in video write.csv(anes, &quot;anes_week8.csv&quot;) Video and RScript You can find the video introducing you to this week‚Äôs method by way of a worked example below. You can also access the code I am typing up in the video in the ‚ÄúCode for Data Analysis‚Äù section. I would encourage you to type it yourself, though, as then code tends to better sink into the depths of your brain üòâ Code for Data Analysis ###################################### # MMM - Week 8 - Multiple Regression ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes_week9.csv&quot;) # Bivariate Regression ############################ model1 &lt;- lm(fttrump1 ~ inc, data = anes) summary(model1) model2 &lt;- lm(fttrump1 ~ age, data = anes) summary(model2) # Multiple Regression ############################ model3 &lt;- lm(fttrump1 ~ inc + age, data = anes) summary(model3) Multiple Regression in R "],["worksheet-week-8.html", "Worksheet Week 8 Self-Assessment Questions12 Multiple Regression in R ‚Äì Guided Example Multiple Regression in R ‚Äì Independent Analysis Homework for Week 9 Solutions", " Worksheet Week 8 Self-Assessment Questions12 Compare bivariate regression and multiple regression. Give an example of the relationship in which you could apply multiple linear regression. How do you interpret partial slope coefficients? How do you interpret adjusted R-Squared in regression analysis? Prepare to interpret the following regression output substantively (what do the coefficients mean, how good is the model fit, etc.) income represents the median household income in a London ward (in ¬£), and turnout represents the turnout at the 2012 mayoral election (in %). Call: lm(formula = turnout ~ income, data = london) Residuals: Min 1Q Median 3Q Max -24.3099 -2.3808 0.5004 3.2679 11.2834 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.955e+01 9.861e-01 19.83 &lt;2e-16 *** income 3.720e-04 2.467e-05 15.08 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 4.594 on 623 degrees of freedom Multiple R-squared: 0.2673, Adjusted R-squared: 0.2661 F-statistic: 227.3 on 1 and 623 DF, p-value: &lt; 2.2e-16 Please stop here and don‚Äôt go beyond this point until we have compared notes on your answers. Please have a look at the indicative solutions to check your answers. Multiple Regression in R ‚Äì Guided Example Download the WDI_PO12Q.csv data set. Data are taken from World Bank (2024), Boix et al. (2018), and Marshall &amp; Gurr (2020). Put it into an appropriate working directory for this seminar and create a dedicated RScript and save it into the same working directory. Import the data set into R: Once again, here is the overview of the variables available and their respective label in Table 12: Table 12: WDI Codebook variable label Country Name Country Name Country Code Country Code year year democracy 0 = Autocracy, 1 = Dictatorship (Boix et al., 2018) gdppc GDP per capita (constant 2010 US$) gdpgrowth Absolute growth of per capita GDP to previous year (constant 2010 US Dollars) enrl_gross School enrollment, primary (% gross) enrl_net School enrollment, primary (% net) agri Employment in agriculture (% of total employment) (modeled ILO estimate) slums Population living in slums (% of urban population) telephone Fixed telephone subscriptions (per 100 people) internet Individuals using the Internet (% of population) tax Tax revenue (% of GDP) electricity Access to electricity (% of population) mobile Mobile cellular subscriptions (per 100 people) service Services, value added (% of GDP) oil Oil rents (% of GDP) natural Total natural resources rents (% of GDP) literacy Literacy rate, adult total (% of people ages 15 and above) prim_compl Primary completion rate, total (% of relevant age group) infant Mortality rate, infant (per 1,000 live births) hosp Hospital beds (per 1,000 people) tub Incidence of tuberculosis (per 100,000 people) health_ex Current health expenditure (% of GDP) ineq Income share held by lowest 10% unemploy Unemployment, total (% of total labor force) (modeled ILO estimate) lifeexp Life expectancy at birth, total (years) urban Urban population (% of total population) polity5 Combined Polity V score Let‚Äôs take the example from Week 7 back up. First re-run the regression I used back then. wdi_life &lt;- lm(gdppc ~ lifeexp, data = wdi) summary(wdi_life) Call: lm(formula = gdppc ~ lifeexp, data = wdi) Residuals: Min 1Q Median 3Q Max -18457 -9877 -4187 4963 78242 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -94306.8 10406.7 -9.062 3.33e-16 *** lifeexp 1503.2 144.4 10.412 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 14690 on 167 degrees of freedom (26 observations deleted due to missingness) Multiple R-squared: 0.3936, Adjusted R-squared: 0.39 F-statistic: 108.4 on 1 and 167 DF, p-value: &lt; 2.2e-16 Interpret the coefficients. Interpreting a coefficient The order in which to interpret a coefficient is as follows: Is it significant? If not, all you can say is that there is no influence. You have falsified the alternative hypothesis. If it is significant, you can interpret its size and direction according to the statistical model (for example, slope coefficnet vs.¬†partial slope coefficient). What does the coefficient mean for the hypothesis? Look at the direction. Is the direction as predicted by the hypothesis? Then you have evidence to support the hypothesis. If the direction is inverse, then you have falsified the hypothesis, even though you have a significant coefficient. Now we use a different regressor, say ‚ÄúUrban population (% of total)‚Äù. Specify the null and the alternative hypotheses. wdi_urban &lt;- lm(gdppc ~ urban, data = wdi) summary(wdi_urban) Call: lm(formula = gdppc ~ urban, data = wdi) Residuals: Min 1Q Median 3Q Max -28588 -10681 -3110 6863 152303 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -16983.43 3872.34 -4.386 1.98e-05 *** urban 542.03 61.74 8.779 1.42e-15 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 19120 on 176 degrees of freedom (17 observations deleted due to missingness) Multiple R-squared: 0.3045, Adjusted R-squared: 0.3006 F-statistic: 77.07 on 1 and 176 DF, p-value: 1.417e-15 Interpret the coefficients. What does this mean for the hypotheses? If we want to assess the influence of both independent variables together, we type: wdi_joint &lt;- lm(gdppc ~ lifeexp + urban, data = wdi) summary(wdi_joint) Call: lm(formula = gdppc ~ lifeexp + urban, data = wdi) Residuals: Min 1Q Median 3Q Max -22570 -8825 -2143 5594 74445 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -74786.14 10690.13 -6.996 6.17e-11 *** lifeexp 1012.17 172.70 5.861 2.41e-08 *** urban 273.74 59.13 4.629 7.37e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 13860 on 166 degrees of freedom (26 observations deleted due to missingness) Multiple R-squared: 0.463, Adjusted R-squared: 0.4565 F-statistic: 71.55 on 2 and 166 DF, p-value: &lt; 2.2e-16 Interpret the coefficients. Bear in mind for your interpretation that these are partial slope coefficients! Because I am nice, I am producing an overview13 of all three regressions in Table 13: ¬† ¬† /* tinytable css entries after */ .table td.tinytable_css_wwaz9nrhgj8a74s59p8a, .table th.tinytable_css_wwaz9nrhgj8a74s59p8a { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; } .table td.tinytable_css_vzdfmw9o7h8669nmpws9, .table th.tinytable_css_vzdfmw9o7h8669nmpws9 { text-align: left; } .table td.tinytable_css_v6q45fnvkaziop86xci3, .table th.tinytable_css_v6q45fnvkaziop86xci3 { text-align: left; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_utlt9f4zwfrbr1b5fei2, .table th.tinytable_css_utlt9f4zwfrbr1b5fei2 { text-align: center; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_ut8zxlrswibxkgbtyto2, .table th.tinytable_css_ut8zxlrswibxkgbtyto2 { text-align: center; } .table td.tinytable_css_pqk6pj5tusgjyow139w4, .table th.tinytable_css_pqk6pj5tusgjyow139w4 { text-align: left; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_o7okhu56gr6jhsgw11cn, .table th.tinytable_css_o7okhu56gr6jhsgw11cn { text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_hvgvpcjjsjt79gha1icc, .table th.tinytable_css_hvgvpcjjsjt79gha1icc { text-align: center; border-bottom: solid black 0.05em; } .table td.tinytable_css_caop6ompvjn8md5q0pgs, .table th.tinytable_css_caop6ompvjn8md5q0pgs { text-align: left; border-bottom: solid black 0.05em; } .table td.tinytable_css_2h1bc5fyzqqym2u1m28t, .table th.tinytable_css_2h1bc5fyzqqym2u1m28t { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_0ttofnaj2szlja7k1c57, .table th.tinytable_css_0ttofnaj2szlja7k1c57 { text-align: left; border-top: solid #d3d8dc 0.1em; text-align: center; } Dependent Variable:per capita GDP Table 13: Regression Models 1. Bivariate(1) Bivariate(2) Multiple(3) + p Life Expectancy (years) 1503.211*** 1012.168*** (144.371) (172.696) Urbanisation 542.033*** 273.735*** (61.743) (59.134) Constant -94306.813*** -16983.431*** -74786.145*** (10406.727) (3872.336) (10690.128) Num.Obs. 169 178 169 R2 0.394 0.305 0.463 R2 Adj. 0.390 0.301 0.456 ¬† ¬† Drawing on what you have learned about the stargazer package in the additional exercises last week, replicate this table. How have the slope coefficients changed? Why? Which model explains the level of GDP best? Why? Specify the SRF for Model 3, paying special attention to notation. Now assume, we want to know whether education has a bearing on the level of GDP. We call: wdi_lit &lt;- lm(gdppc ~ literacy, data = wdi) and also add it to the joint model: wdi_joint1 &lt;- lm(gdppc ~ lifeexp + urban + literacy, data = wdi) This should lead to these results: ¬† ¬† /* tinytable css entries after */ .table td.tinytable_css_wak92yxrc715mgvd6c7a, .table th.tinytable_css_wak92yxrc715mgvd6c7a { text-align: center; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_ulflswu7ntmvgpmpz7ez, .table th.tinytable_css_ulflswu7ntmvgpmpz7ez { text-align: left; border-top: solid #d3d8dc 0.1em; text-align: center; } .table td.tinytable_css_rt3pa4ziyw4mok4b1h3m, .table th.tinytable_css_rt3pa4ziyw4mok4b1h3m { text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_g6iedpqgwhjq98uihrks, .table th.tinytable_css_g6iedpqgwhjq98uihrks { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; } .table td.tinytable_css_70aaeeeeoz263n32a9sm, .table th.tinytable_css_70aaeeeeoz263n32a9sm { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_6zmxn3smaw2wtx1jdo6y, .table th.tinytable_css_6zmxn3smaw2wtx1jdo6y { text-align: left; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_6eimy5639g72dr58wix0, .table th.tinytable_css_6eimy5639g72dr58wix0 { text-align: left; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_4nvoa9eu9ny97v6gjw99, .table th.tinytable_css_4nvoa9eu9ny97v6gjw99 { text-align: center; } .table td.tinytable_css_2wprpgm970f1dbp778w2, .table th.tinytable_css_2wprpgm970f1dbp778w2 { text-align: left; } .table td.tinytable_css_1emy158moel7sk8xa36a, .table th.tinytable_css_1emy158moel7sk8xa36a { text-align: center; border-bottom: solid black 0.05em; } .table td.tinytable_css_1086csjdf6zboqcj9tb7, .table th.tinytable_css_1086csjdf6zboqcj9tb7 { text-align: left; border-bottom: solid black 0.05em; } Dependent Variable:per capita GDP Table 14: Regression Models 2. (1) (2) (3) (4) (5) + p Life Expectancy (years) 1503.211*** 1012.168*** 973.985* (144.371) (172.696) (411.375) Urbanisation 542.033*** 273.735*** 227.126* (61.743) (59.134) (83.427) Literacy 258.407* -221.731 (97.381) (142.455) Constant -94306.813*** -16983.431*** -74786.145*** -12967.003 -55246.837** (10406.727) (3872.336) (10690.128) (8529.810) (19311.126) Num.Obs. 169 178 169 40 39 R2 0.394 0.305 0.463 0.156 0.497 R2 Adj. 0.390 0.301 0.456 0.134 0.454 ¬† ¬† In Model 5 the coefficient for literacy has turned insignificant. Reproduce the results in Table 4 to find out which variable takes away the significance. ¬† ¬† /* tinytable css entries after */ .table td.tinytable_css_vu1lg4evyqloeytx4461, .table th.tinytable_css_vu1lg4evyqloeytx4461 { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_sjsccy4cmr7nfamtvqe0, .table th.tinytable_css_sjsccy4cmr7nfamtvqe0 { text-align: left; } .table td.tinytable_css_riwf57oduo7n4dw0y3yh, .table th.tinytable_css_riwf57oduo7n4dw0y3yh { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; } .table td.tinytable_css_rb20wzcecthpzz2oatfa, .table th.tinytable_css_rb20wzcecthpzz2oatfa { text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_pmukg6bviiog8muwf749, .table th.tinytable_css_pmukg6bviiog8muwf749 { text-align: center; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_j9lg8ykfpyypczorscko, .table th.tinytable_css_j9lg8ykfpyypczorscko { text-align: left; border-top: solid #d3d8dc 0.1em; text-align: center; } .table td.tinytable_css_fmmnkhi8ii4fvepjyung, .table th.tinytable_css_fmmnkhi8ii4fvepjyung { text-align: center; } .table td.tinytable_css_9m5vfpf1xdtrkmto5329, .table th.tinytable_css_9m5vfpf1xdtrkmto5329 { text-align: left; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_9lzotq8iyxmbeys6sx80, .table th.tinytable_css_9lzotq8iyxmbeys6sx80 { text-align: left; border-bottom: solid black 0.05em; } .table td.tinytable_css_6cycd3osf8llndtu7d0m, .table th.tinytable_css_6cycd3osf8llndtu7d0m { text-align: center; border-bottom: solid black 0.05em; } .table td.tinytable_css_5opnv7fv0to2lgjydnt7, .table th.tinytable_css_5opnv7fv0to2lgjydnt7 { text-align: left; border-bottom: solid #d3d8dc 0.05em; } Dependent Variable:per capita GDP Table 15: Regression Models 3. (1) (2) (3) + p Life Expectancy (years) 1483.785*** (397.567) Urbanisation 315.375*** (77.633) Literacy 258.407* -223.305 28.390 (97.381) (154.620) (99.706) Constant -12967.003 -77851.339*** -12399.608+ (8529.810) (18924.058) (7189.937) Num.Obs. 40 39 40 R2 0.156 0.390 0.417 R2 Adj. 0.134 0.357 0.385 ¬† ¬† What can we conclude from this investigation? Does the variable infant have the same effect? What do you conclude from this? Which measurement explains GDP better, life or infant? ¬† ¬† /* tinytable css entries after */ .table td.tinytable_css_wa7g3bdqasik54nf8d4t, .table th.tinytable_css_wa7g3bdqasik54nf8d4t { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_v1uqywm9ifvi3yxsczj2, .table th.tinytable_css_v1uqywm9ifvi3yxsczj2 { text-align: left; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_uykxrzp0pkkytbwcwn8u, .table th.tinytable_css_uykxrzp0pkkytbwcwn8u { text-align: left; border-bottom: solid black 0.05em; } .table td.tinytable_css_sfweql705l54p8u2vmhl, .table th.tinytable_css_sfweql705l54p8u2vmhl { text-align: center; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_ok44it6gsxgadwx9xcby, .table th.tinytable_css_ok44it6gsxgadwx9xcby { text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_mot3g5pvqakw7gtdn62w, .table th.tinytable_css_mot3g5pvqakw7gtdn62w { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; } .table td.tinytable_css_ljtdsajgnocb52raiazl, .table th.tinytable_css_ljtdsajgnocb52raiazl { text-align: left; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_aq15zrs34u8ireasgobi, .table th.tinytable_css_aq15zrs34u8ireasgobi { text-align: left; border-top: solid #d3d8dc 0.1em; text-align: center; } .table td.tinytable_css_6ae8niaw8mg97hno6bf2, .table th.tinytable_css_6ae8niaw8mg97hno6bf2 { text-align: left; } .table td.tinytable_css_3p0ogkzg4s8u5uy8yhgc, .table th.tinytable_css_3p0ogkzg4s8u5uy8yhgc { text-align: center; border-bottom: solid black 0.05em; } .table td.tinytable_css_33vrk5jgakvi0xbd2jp3, .table th.tinytable_css_33vrk5jgakvi0xbd2jp3 { text-align: center; } Dependent Variable:per capita GDP Table 16: Regression Models 4. life infant + p Life Expectancy (years) 1503.211*** (144.371) Infant Mortality (per 1,000 live births) -524.111*** (73.885) Constant -94306.813*** 26467.135*** (10406.727) (2257.385) Num.Obs. 169 178 R2 0.394 0.222 R2 Adj. 0.390 0.218 ¬† ¬† Multiple Regression in R ‚Äì Independent Analysis Before you start with these, please pause and let Flo/Luis know that you are done. We will compare notes on your answers up to this point, to make sure that you are on the right track for the independent exercises. Use the wdi data frame. Set polity5 as the dependent variable, and choose three sensible variables which you believe could influence democracy. Note that the Polity V Score codes regimes from -10 (indicating perfect autocracy) to +10 (indicating perfect democracy). State the null- and alternative hypotheses for each of the independent variables chosen. Plot two of the bivariate models in a scatter plot (black points) with fitted regression line (in red). Use base R, or ggplot. Does the direction of influence agree with your hypotheses? Run all possible regression models, using a bottom-up strategy. Construct a stargazer table to present the results. Specify the Sample Regression Function (SRF) for a bivariate model (Model A), a multivariate model with two independent variables (Model B), and for the model using all three independent variables (Model C). Interpret the intercept and one of the slope coefficients in Models A, B, and C. Interpret the model fit measure for Models A, B, and C. Which model explains democracy best? Why?. What do we conclude with respect to the hypotheses stated in Exercise 2 from this analysis? Collate a PowerPoint (Keynote) presentation with one slide for each of the preceding nine points. We will discuss this in Week 9. Homework for Week 9 There is no separate reading for the Week 9 seminar Work through this week‚Äôs flashcards to familiarise yourself with the relevant R functions. Find an example for each NEW function and apply it in R to ensure it works Complete the Week 8 Moodle Quiz Work through the Week 9 ‚ÄúMethods, Methods, Methods‚Äù Section. Revise the material of Weeks 1-5 and note questions you have whilst doing this. Solutions You can find the Solutions in the Downloads Section. Some of the content of this worksheet is taken from Reiche (forthcoming).‚Ü©Ô∏é For disclosure: the following regression tables have been produced with the package modelsummary (Arel-Bundock, 2022) to which I will switch fully in 2025/26.‚Ü©Ô∏é "],["glossary-4.html", "Glossary", " Glossary Table 17: Glossary Week 8 Term Description adjusted rsquared The coefficient of determination for multiple regression. model building Running a number of regression models, each testing a different combination of variables. parsimony Refers to the principle . partial slope coefficient A partial slope coefficient measures the influence of a variable in multiple regression, holding all other independent variables in the model constant "],["flashcards-7.html", "Flashcards", " Flashcards New Functions This Week The data are available as a .csv file. R Functions This Week The data are available as a .csv file. All R Functions So Far The data are available as a .csv file. "],["methods-methods-methods-6.html", "Methods, Methods, Methods Data Prep Video and RScript", " Methods, Methods, Methods We have sort of covered how to create dummy variables already on PO11Q, but for completeness‚Äô sake here is an exploration on how to create them, include them in regression models, and how to interpret them (that all-important reference category‚Ä¶). Just as last week we will be working with the American National Election Studies (ANES), and to be more precise with the pilot survey conducted before the 2020 presidential election. If you haven‚Äôt already done so, you will have to register with ANES in order to download the data set. To do so, please follow this link. Data Prep Place the ANES data in a folder which you will be using as a working directory for this session. Open the ‚ÄúCode for Data Preparation‚Äù below, and copy this into an RScript. Remember to adjust the working directory with the setwd() command at the beginning. Then run the RScript and you will be ready to proceed to the video. Code for Data Preparation ###################################### # MMM - Week 9 - Dummy Variables ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes.csv&quot;) # Get rid of missing values for variables used in analysis today ## 999 is equivalent to NA, so needs to be recoded anes$fttrump1 &lt;- with(anes, replace(fttrump1, fttrump1 == 999, NA)) anes$income &lt;- with(anes, replace(income, income == 99, NA)) anes &lt;- filter(anes, !is.na(fttrump1), !is.na(income)) # Label variable `sex` anes$sex &lt;- factor(anes$sex) anes &lt;- anes %&gt;% mutate(sex= recode(sex,&quot;1&quot;=&quot;Male&quot;, &quot;2&quot;=&quot;Female&quot;)) anes$sex &lt;- as.factor(anes$sex) # Turn income variable into a numerical variable with mid-points of each level anes$income &lt;- factor(anes$income) anes &lt;- anes %&gt;% mutate(income_fac = recode(income, &#39;1&#39;= &quot;2500&quot;, &#39;2&#39;= &quot;7499.5&quot;, &#39;3&#39;= &quot;12499.5&quot;, &#39;4&#39;= &quot;17499.5&quot;, &#39;5&#39;= &quot;22499.5&quot;, &#39;6&#39;= &quot;27499.5&quot;, &#39;7&#39;= &quot;32499.5&quot;, &#39;8&#39;= &quot;37499.5&quot;, &#39;9&#39;= &quot;42499.5&quot;, &#39;10&#39;= &quot;47499.5&quot;, &#39;11&#39;= &quot;52499.5&quot;, &#39;12&#39;= &quot;57499.5&quot;, &#39;13&#39;= &quot;62499.5&quot;, &#39;14&#39;= &quot;67499.5&quot;, &#39;15&#39;= &quot;72499.5&quot;, &#39;16&#39;= &quot;77499.5&quot;, &#39;17&#39;= &quot;82499.5&quot;, &#39;18&#39;= &quot;87499.5&quot;, &#39;19&#39;= &quot;92499.5&quot;, &#39;20&#39;= &quot;97499.5&quot;, &#39;21&#39;= &quot;112499.5&quot;, &#39;22&#39;= &quot;137499.5&quot;, &#39;23&#39;= &quot;162499.5&quot;, &#39;24&#39;= &quot;187499.5&quot;, &#39;25&#39;= &quot;224999.5&quot;, &#39;26&#39;= &quot;500000&quot;)) anes$inc &lt;- as.numeric(as.character(anes$income_fac)) # save data set for use in video write.csv(anes, &quot;anes_week9.csv&quot;) Video and RScript You can find the video introducing you to this week‚Äôs method by way of a worked example below. You can also access the code I am typing up in the video in the ‚ÄúCode for Data Analysis‚Äù section. I would encourage you to type it yourself, though, as then code tends to better sink into the depths of your brain üòâ Code for Data Analysis ###################################### # MMM - Week 9 - Dummy Variables ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes_week10.csv&quot;) anes$sex &lt;- as.factor(anes$sex) # Bivariate Regression ############################ model1 &lt;- lm(fttrump1 ~ sex, data = anes) summary(model1) anes &lt;- anes %&gt;% mutate(sex = relevel(sex, ref = &quot;Male&quot;)) table(anes$sex) model2 &lt;- lm(fttrump1 ~ sex, data = anes) summary(model2) # Multiple Regression ############################ model3 &lt;- lm(fttrump1 ~ inc + sex, data = anes) summary(model3) Dummy Variables in R "],["worksheet-week-9.html", "Worksheet Week 9 Group Work ‚Äì Self-Reflection14 Working with Regression Analysis Going Further Transformation of Variables Homework for Week 10 Solutions", " Worksheet Week 9 Group Work ‚Äì Self-Reflection14 How does the concept of the conditional expected value relate to the interpretation of coefficients in multiple regression? How do you select variables for a multiple regression model? Why do we apply non-linear transformations to variables? How do you interpret the effect of a logarithmized variable? Using data from London wards (London Data Store, 2013) the regression models in Table 18 explain voter turnout in the 2012 mayoral elections. interpret the intercept in Model 1 interpret the slope coefficient in Model 1 interpret the slope coefficients in Model 3 explain why the size effect of the slope coefficients in Models 1 and 2 is so different interpret the model fit measure in Model 3 ¬† /* tinytable css entries after */ .table td.tinytable_css_yf3xrzim7i6b1hma1oog, .table th.tinytable_css_yf3xrzim7i6b1hma1oog { text-align: center; border-bottom: solid black 0.05em; } .table td.tinytable_css_w6pgvwz3rkmzhrubanta, .table th.tinytable_css_w6pgvwz3rkmzhrubanta { text-align: left; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_r8vzixbd9fx91k7wwenh, .table th.tinytable_css_r8vzixbd9fx91k7wwenh { text-align: center; } .table td.tinytable_css_ngmx9359ir86nhn7fhso, .table th.tinytable_css_ngmx9359ir86nhn7fhso { text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_lclo8ynbeezo4dg1naw6, .table th.tinytable_css_lclo8ynbeezo4dg1naw6 { text-align: center; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_ict46fip99qstmk1miic, .table th.tinytable_css_ict46fip99qstmk1miic { text-align: left; border-bottom: solid black 0.05em; } .table td.tinytable_css_f4m25oiabw76ey6cj8bd, .table th.tinytable_css_f4m25oiabw76ey6cj8bd { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_epmao9xr5biy7r1ciuaa, .table th.tinytable_css_epmao9xr5biy7r1ciuaa { text-align: center; border-top: solid #d3d8dc 0.1em; text-align: center; } .table td.tinytable_css_aquarwvmkvev6do2mau2, .table th.tinytable_css_aquarwvmkvev6do2mau2 { text-align: left; border-top: solid #d3d8dc 0.1em; text-align: center; } .table td.tinytable_css_agyctuxg88lv10h6q6z4, .table th.tinytable_css_agyctuxg88lv10h6q6z4 { text-align: left; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_7qqorrceucalnbpjzrf1, .table th.tinytable_css_7qqorrceucalnbpjzrf1 { text-align: left; } Dependent Variable:Turnout in 2012 Mayoral Elections Table 18: Regression Models for Self-Reflection Exercises. Bivariate(1) Bivariate(2) Multiple(3) + p Age (median) 0.740*** 0.724*** (0.063) (0.064) Crime Rate (per 1,000) -0.009** -0.005+ (0.003) (0.003) Constant 7.555*** 34.900*** 8.536*** (2.284) (0.319) (2.340) Num.Obs. 625 625 625 R2 0.180 0.015 0.184 R2 Adj. 0.179 0.014 0.182 ¬† Please stop here and don‚Äôt go beyond this point until we have compared notes on your answers. Working with Regression Analysis We will be using the ‚Äúcrime.csv‚Äù data available in the Downloads Section to analyse attitudes and experiences of crime in England and Wales. The data set contains several variables relating to questions asked about experience and perceptions of crime to a representative sample along with demographic details on the respondents (University of Manchester, Cathie Marsh Institute for Social Research (CMIST), UK Data Service, Office for National Statistics, 2019). For variable labels, please consult the Crime Data Code Book. Data Analysis Each respondent was randomly assigned to a different module, indicated by split and only asked a subsection of the questions. The antisocx variable is part of module A and asks for a score from respondents on how much antisocial behaviour is in the neighbourhood. Previous research has suggested men perceive more antisocial behaviour in rural areas than urban areas. Create a new data set for those who were chosen for the ‚ÄòA‚Äô module. Call this crime.a. Create a linear model using only male respondents from crime.a with the dependent variable antisocx and the independent variable rural2. Do your findings support previous research? Test the same model using only women. How do the two models differ? We will now be using the full crime data frame. The wburgl variable asks respondents how worried they are about being burgled with answers ranging from ‚ÄúVery worried‚Äù to ‚ÄúNot at all worried‚Äù along with ‚ÄúNot applicable‚Äù and ‚ÄúDon‚Äôt know.‚Äù Recode those with ‚ÄúNot applicable‚Äù or ‚ÄúDon‚Äôt know‚Äù as NAs. b.Using agegrp7 and wburgl as continuous variables, test the hypothesis that older people are more worried about being burgled. Using a dummy variable test whether those over 65 have are more worried about burglary then those who are younger. Using dummies test whether any of the age groups differ significantly from the youngest age group. What does the intercept in each of the three models represent? Going Further I have written these exercises so that you can practice in R a little more. These are a bit more demanding, however. If you skip this section, please make sure to do the exercises in the next section, as this taps into the variable transformations we explored in the lecture. There are five variables which ask how worried the respondent is about being the victim of various crimes: Create an additive variable called worry from these variables so that a score of 0 indicates the respondent answered all ‚ÄúNot at all worried‚Äù and a score of 15 indicates the respondent answered all ‚ÄúVery worried.‚Äù (Tip: Make sure to clean the variables for NAs). What are the mode, mean and median for worry? Describe the variable educat3. How could it be modified to be used as a continuous variable? Using educat3 as both a continuous and factor variable evaluate the statement ‚ÄúWorry about being a victim of crime is higher in those with lower education levels.‚Äù What are the \\(R^2\\) values for the two models calculated? Which is higher? Does this make that model better than the other? Calculate \\(97.5\\%\\) confidence intervals for the coefficients for those with GCSEs and those with Degrees. What does this tell you? Transformation of Variables This Section uses the london_exercises data set available in the Downloads Section. Data are taken from London Data Store (2013). This document provides a full codebook. Unemployment rate, defined as the ratio of people in full time employment to population of working age is often said to be related to crime. Generate an unemployment rate variable for each of the wards. It is theorised that unemployment is a driving factor behind crime rates. Plot a scatter graph with unemployment rate, crime rate, and the regression line that may be used to evaluate the theory. Describe the plot and the best fit line. Plot the graph again excluding wards with a crime rate greater than 500. Describe the plot and the best fit line. Plot another graph excluding wards with a crime rate of over 500 with the crime rate log transformed. Describe the plot and the best fit line. Build both models (b and c). Interpret both including the effect size. Which model fits the data better? Homework for Week 10 Work through this week‚Äôs flashcards to familiarise yourself with the relevant R functions. Find an example for each NEW function and apply it in R to ensure it works Complete the Week 9 Moodle Quiz Revise the material of weeks 7-9 and note any questions you might have Work through the Week 10 ‚ÄúMethods, Methods, Methods‚Äù Section. Solutions You can find the Solutions in the Downloads Section. All exercises are a reproduction from Reiche (forthcoming).‚Ü©Ô∏é "],["glossary-5.html", "Glossary", " Glossary Table 19: Glossary Week 9 Term Description categorical Describing the qualitative categories of a characteristic, for example different religions dichotomous Can only assume two mutually exclusive, but internally homogeneous qualitative categories dummy variable Dummy variables are dichotomous, categorical variables which indicate the presence or the absence of a characteristic. logarithm Logarithm is defined as the exponent or power to which a base must be raised to yield a given number. Expressed mathematically, \\(x\\) is the logarithm of \\(n\\) to the base \\(b\\) if \\(b^x = n\\), in which case \\(x = log_b n\\) (Murray, 2023) reference category The category of a dummy variable in respect to which the effect on the value of the dependent variable is displayed "],["flashcards-8.html", "Flashcards", " Flashcards New Functions This Week The data are available as a .csv file. R Functions This Week The data are available as a .csv file. All R Functions So Far The data are available as a .csv file. "],["methods-methods-methods-7.html", "Methods, Methods, Methods Data Prep Video and RScript", " Methods, Methods, Methods This week we will be testing two of the CLAs, namely homoscedasticity and colinearity. As always, we will use the American National Election Studies (ANES). I will draw on the data set and regression models from Week 8 to assess these assumptions. Data Prep Place the ANES data in a folder which you will be using as a working directory for this session. Open the ‚ÄúCode for Data Preparation‚Äù below, and copy this into an RScript. Remember to adjust the working directory with the setwd() command at the beginning. Then run the RScript and you will be ready to proceed to the video. Code for Data Preparation ###################################### # MMM - Week 8 - Data Preparation ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read_csv(&quot;anes.csv&quot;) # Get rid of missing values for variables used in analysis today ## 999 is equivalent to NA, so needs to be recoded anes$fttrump1 &lt;- with(anes, replace(fttrump1, fttrump1 == 999, NA)) anes$income &lt;- with(anes, replace(income, income == 99, NA)) anes &lt;- filter(anes, !is.na(fttrump1), !is.na(age), !is.na(income)) # Turn income variable into a numerical variable with mid-points of each level anes$income &lt;- factor(anes$income) table(anes$income) anes &lt;- anes %&gt;% mutate(income_fac = recode(income, &#39;1&#39;= &quot;2500&quot;, &#39;2&#39;= &quot;7499.5&quot;, &#39;3&#39;= &quot;12499.5&quot;, &#39;4&#39;= &quot;17499.5&quot;, &#39;5&#39;= &quot;22499.5&quot;, &#39;6&#39;= &quot;27499.5&quot;, &#39;7&#39;= &quot;32499.5&quot;, &#39;8&#39;= &quot;37499.5&quot;, &#39;9&#39;= &quot;42499.5&quot;, &#39;10&#39;= &quot;47499.5&quot;, &#39;11&#39;= &quot;52499.5&quot;, &#39;12&#39;= &quot;57499.5&quot;, &#39;13&#39;= &quot;62499.5&quot;, &#39;14&#39;= &quot;67499.5&quot;, &#39;15&#39;= &quot;72499.5&quot;, &#39;16&#39;= &quot;77499.5&quot;, &#39;17&#39;= &quot;82499.5&quot;, &#39;18&#39;= &quot;87499.5&quot;, &#39;19&#39;= &quot;92499.5&quot;, &#39;20&#39;= &quot;97499.5&quot;, &#39;21&#39;= &quot;112499.5&quot;, &#39;22&#39;= &quot;137499.5&quot;, &#39;23&#39;= &quot;162499.5&quot;, &#39;24&#39;= &quot;187499.5&quot;, &#39;25&#39;= &quot;224999.5&quot;, &#39;26&#39;= &quot;500000&quot;)) anes$inc &lt;- as.numeric(as.character(anes$income_fac)) # save data set for use in video write.csv(anes, &quot;anes_week10.csv&quot;) Video and RScript You can find the video introducing you to this week‚Äôs method by way of a worked example below. You can also access the code I am typing up in the video in the ‚ÄúCode for Data Analysis‚Äù section. I would encourage you to type it yourself, though, as then code tends to better sink into the depths of your brain üòâ Code for Data Analysis ###################################### # MMM - Week 10 - BLUE ###################################### # Set WD setwd() # Load packages library(tidyverse) # Load data set anes &lt;- read.csv(&quot;anes_week8.csv&quot;) # Regression Models ############################ model1 &lt;- lm(fttrump1 ~ inc, data = anes) model2 &lt;- lm(fttrump1 ~ age, data = anes) model3 &lt;- lm(fttrump1 ~ inc + age, data = anes) # Testing for Homoscedasticity ################################ library(lmtest) #Null Hypothesis: Homoscedasticity #Alternative: Heteroscedasticity bptest(model1) bptest(model2) library(sandwich) coeftest(model2, vcov = vcovHC(model2, type=&quot;HC3&quot;)) # Testing for Collinearity ################################ library(car) vif(model3) Making Your Regression BLUE "],["worksheet-week-10.html", "Worksheet Week 10 Self-Assessment Questions Testing the Classical Linear Assumptions The Gauss-Markov Theorem", " Worksheet Week 10 Self-Assessment Questions How do the mathematical properties of OLS (Week 5) differ from the Classical Linear Assumptions? Why is observed heteroscedasticity a problem that needs addressing? What happens in a model with (multi-)collinearity? Does the assumption of linearity in the Gauss-Markov Theorem preclude non-linear transformations? Why / why not? Please stop here and don‚Äôt go beyond this point until we have compared notes on your answers. Testing the Classical Linear Assumptions For this worksheet we will be using the london data set from the lectures, this time with the following variables: Table 20: Codebook for london_11 Data Set Variable Label Year const Parliamentary constituency n/a gcse An average score based on a pupil‚Äôs best eight grades in a group of GCSEs. The maximum a pupil can achieve is 90 points 2019 houseprice Median house price, average across four quarters, in GBP 2019 idaci The Income Deprivation Affecting Children Index rank - how it compares to other constituencies 2015/2016 income Mean income by constituency 2017/18 Data are taken from GOV.UK (2013), London Data Store (2010), and House of Commons Library (n.d.). Homoscedasticity Load the data set london_11.csv as an object called london Subset the data to a random sample as follows: set.seed(123) london_sam &lt;- sample_frac(london, 0.65, replace=FALSE) Regress GCSE scores on income and interpret the results. model1 &lt;- lm(gcse ~ income, data=london_sam) Breusch-Pagan Test by Hand Extract the residuals from model 1 and store their squared values in a new object called ressq. ressq &lt;- resid(model1)^2 ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†b. Regress the squared residuals on the original independent variable. model1res &lt;- lm(ressq~income, data=london_sam) ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†c.¬†Store the number of observations of this new model in an object called N. N &lt;- nobs(model1res) ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†d.¬†Obtain the model fit measure R\\(^2\\) for this model. ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†e. Calculate the test-statistic for the Breusch-Pagan test as the product of N and R\\(^2\\). chisq &lt;- 0.001857*N ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†f.¬†Conduct a Chi-Squared test with one degree of freedom. pchisq(chisq, df=1, lower.tail=FALSE) [1] 0.7676653 Breusch-Pagan Test with the lmtest package. Install and load the lmtest package ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†b. Call bptest(model1) ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†c.¬†Compare the results with the results obtained in Exercise 4f. Heteroscedasticity Now let‚Äôs introduce heteroscedasticity: london_heterosc &lt;- filter(london, income&lt;28000 | income&gt;100000) Why does this code lead to heteroscedasticity? ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†b. Estimate a new model, and note the significance of coefficients. model2 &lt;- lm(gcse ~ income, data=london_heterosc) ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†c.¬†Conduct a Breusch-Pagan Test with the lmtest package. ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†d.¬†Install and load the sandwich package. library(sandwich) ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†e. The sandwich package replaces \\(\\Omega\\) with a new diagonal which takes into account ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†heteroscedasticity. The default is HC3 ‚Äì if you ever work with somebody using Stata then ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†you need to replace this with HC1 to obtain the same results. Conduct a significance test with ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†robust standard errors (with the sandwich function coeftest): coeftest(model2, vcov = vcovHC(model2, type=&quot;HC3&quot;)) ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†f.¬†Compare the significance to the results in 6b and explain the reason for the difference. ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†g. Estimate a model of your own choice with gcse as your dependent variable. ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†h. Conduct the Breusch-Pagan test ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†i. by hand ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†ii. with the lmtest package (Multi-)Collinearity15 In this Section, we will be testing for collinearity. We can do so with correlation analysis, which assesses to what degree two variables vary together. As such, this method is limited to pairwise comparisons between variables. It is conceivable, and indeed often the case, however, that one variable is functionally related to two or more other independent variables, such as \\[\\begin{equation*} x_{1,i} = 0.2 x_{2,i }- 1.7 x_{3,i} \\end{equation*}\\] We refer to this situation as multicollinearity. In order to detect it, we need to test for the functional dependence of each independent variable on the remaining independent variables in the model. We can do so by employing secondary regression models, not unlike in the Breusch-Pagan Test (see lecture slides). We specify K secondary regression models, each adopting one of our K independent variables as its dependent variable. Let us specify such a function for \\(x_1\\): \\[\\begin{equation*} x_{1,i} = \\alpha_0 + \\alpha_1 x_{2,i} + \\alpha_2 x_{3,i} + ... + \\alpha_{k-1} x_{k,i} + v_i \\end{equation*}\\] where \\(\\alpha\\) denotes our new regression coefficients, and \\(v_i\\) represents a random error term. For the remaining independent variables, the functions would look as follows: \\[\\begin{align*} x_{2,i} &amp;= \\alpha_0 + \\alpha_1 x_{1,i} + \\alpha_2 x_{3,i} + \\alpha_3 x_{4,i} + ... + \\alpha_{k-1} x_{k,i} + v_i \\\\ x_{3,i} &amp;= \\alpha_0 + \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{4,i} + ... + \\alpha_{k-1} x_{k,i} + v_i \\\\ \\vdots \\\\ x_{k,i} &amp;= \\alpha_0 + \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + ... + \\alpha_{k-1} x_{k-1,i} + v_i \\end{align*}\\] In order to quantify how well each of the K regression functions explains the respective independent variable, we are going to use Adjusted R-Squared. We will note the \\(\\bar{R}^2\\) of each individual regression as \\(\\bar{R}_j^2\\) where j runs from 1 to k, or \\(j=1,...,k\\). \\(\\bar{R}_j^2\\) in itself already provides useful information, but we can do better than this. We can use \\(\\bar{R}_j^2\\) to develop a measure which tells us how much larger the observed variance of a coefficient is compared to a scenario in which the variable was totally functionally independent from the other independent variables in the model. We call this measure variance inflation factor and define it as follows: \\[\\begin{equation} \\text{VIF}_j = \\frac{1}{1-\\bar{R}_j^2} \\end{equation}\\] Its size is solely determined by \\(\\bar{R}_j^2\\). The better a model explains the respective independent variable, the closer \\(\\bar{R}_j^2\\) will be to one, increasing the size of VIF\\(_j\\). A commonly adopted threshold for classing a variable as (multi-)collinear is VIF=10. This threshold is completely arbitrary, but has nonetheless managed to establish itself in regression analysis. We will now use london_sam data frame to put theory into practice. Regress GCSE scores on and in a multiple regression model. Interpret the results. model3 &lt;- lm(gcse ~ income + idaci, data=london_sam) Install and load the package. library(car) Calculate the Variance Inflation Factor (VIF) for this model as follows: vif(model3) Interpret the results. Regress GCSE scores on houseprice. Store the results in an object called model4. Note the significance of the slope coefficient and interpret the results. Let‚Äôs introduce some collinearity by estimating the following model: model5 &lt;- lm(gcse ~ income + houseprice, data=london_sam) Calculate the VIF for model 5. Interpret the results. Drawing on the results of Exercise 7, explain the significance of the slope coefficients of Model 1 (Exercise 3 in the previous section) and Model 4 (Exercise 6 of this section). The Gauss-Markov Theorem Explain in your own words, what BLUE means. According to Malinvaud, the assumption that \\(E(\\epsilon_{i}|X_{i})=0\\) is quite important. To see this, consider the PRF: \\(Y=\\beta_{0}+\\beta_{1}X_{i}+\\epsilon_{i}\\). Now consider two situations: (1) \\(\\beta_{0}=0\\), \\(\\beta_{1}=1\\) and \\(E(\\epsilon_{i})=0\\); and (2) \\(\\beta_{0}=1\\), \\(\\beta_{1}=0\\) and \\(E(\\epsilon_{i})=X_{i}-1\\). Now take the expectation of the PRF conditional upon \\(X\\) in those two cases, and see if you agree with Malinvaud about the significance of the assumption \\(E(\\epsilon_{i}|X_{i})=0\\).16 This discussion is a verbatim reproduction of Reiche (forthcoming).‚Ü©Ô∏é Exercise taken from Gujarati &amp; Porter (2009)‚Ü©Ô∏é "],["homework.html", "Homework Solutions", " Homework Work through this week‚Äôs flashcards to familiarise yourself with the relevant R functions. Complete the Week 10 Moodle Quiz There will be an exam revision session in Week 2 of term 3. For this, please complete the Sample Case Study Prepare for the exam in term 3. Solutions You can find the Solutions in the Downloads Section. "],["glossary-6.html", "Glossary", " Glossary Table 21: Glossary Week 10 Term Description autocorrelation The value of one error term does not allow us to predict the value of another error term. As such their covariances must be zero collinearity If two variables are functionally dependent on each other we call these collinear. Should this apply to multiple variables at the same time we call these multi-collinear. (multi-)collinearity exists if ‚Äì and only if ‚Äì the values follow this function precisely. Such a situation is rare, as usually variables are more loosely related to one another covariance A measure which assesses the degree to which the values of two variables (\\(X_i\\) and \\(X_j\\)) vary together (their joint variability). heteroscedasticity The variability of the error terms changes for different observations \\(X\\) homoscedasticity Refers to a constant variance of the error terms law of iterative expectations According to this law, ‚Äúthe expected value of X is equal to the expectationover the conditional expectation of X given Y‚Äù (Robinson, 2022) multicollinearity A situation in which an independent variable is a function of multiple other independent variables in the regression model omitted variable bias If you omit an important variable in a regression model, it will bias the size of other coefficients if the variables are correlated. outer product The outer product of two vectors results in a matrix in which each element is the product of corresponding elements from the first vector (rows) and the second vector (columns). robust standard errors Also known as Huber-White standard errors, correct for heteroscedasticity by ‚Äú[adjusting] the model-based standard errors using the empirical variability of the model residuals‚Äù (Mansournia et al., 2020, p. 347) time-series data Time-series data review a certain characteristic over time \\(t\\), where \\(t\\) runs from 1 to \\(T\\) Variance-Covariance Matrix A variance-covariance matrix is a square matrix that encapsulates the variances of different variables on its diagonal and the covariances between pairs of variables in its off-diagonal elements.¬† Variance Inflation Factor (VIF) A measure to quantify the how much larger the observed variance of a coefficient is compared to a scenario in which the variable was totally functionally independent from the other independent variables in the model "],["flashcards-9.html", "Flashcards", " Flashcards New Functions This Week The data are available as a .csv file. R Functions This Week The data are available as a .csv file. All R Functions Used on the Module The data are available as a .csv file. "],["downloads.html", "Downloads Documents Data Sets R Scripts", " Downloads Yes, all solutions and all RScripts are available to you without the silly time restriction I imposed in term 1. The reason is that I have come to realise that I am operating a module in a university, and not in a kindergarten. Of course, you can download and look at the solutions before you have given the exercises a go yourself first. By all means, cheat. But I can‚Äôt promise you that you will learn very much. It‚Äôs your choice. Documents PO12Q Bibliography Statistical Tables Week 1 Worksheet Solutions Boix et al.¬†(2018) Paper Week 2 Worksheet Solutions Week 4 Worksheet Solutions Week 4 Regression Calculations Week 5 Regression Calculations Week 7 Worksheet Solutions Week 7 Regression Calculations Week 7 Solutions to Additional Exercises Week 9 Crime Data Code Book Week 9 london_exercises Code Book Week 10 Worksheet Solutions Data Sets crime.csv london_11.csv london_exercises.csv PO12Q_4.xslx simd.csv WDI_PO12Q.csv R Scripts Week 3 R Solutions Week 8 R Solutions Week 9 R Solutions Week 10 R Solutions "],["glossary-7.html", "Glossary", " Glossary Unless otherwise noted, the definitions are taken from Reiche (forthcoming). Table 22: Glossary for PO12Q Term Description adjusted rsquared The coefficient of determination for multiple regression. autocorrelation The value of one error term does not allow us to predict the value of another error term. As such their covariances must be zero categorical Describing the qualitative categories of a characteristic, for example different religions coefficient A coefficient is a numerical expression which is multiplied with the value of a variable coefficient of determination Indicates the proportion of the variation in the dependent variable which is explained through the independent variable. It is defined as \\(\\frac{\\text{Explained Sum of Squares}}{\\text{Total Sum of Squares}}\\) collinearity If two variables are functionally dependent on each other we call these collinear. Should this apply to multiple variables at the same time we call these multi-collinear. (multi-)collinearity exists if ‚Äì and only if ‚Äì the values follow this function precisely. Such a situation is rare, as usually variables are more loosely related to one another conditional expectation function see Population Regression Function (PRF) confidence interval A confidence interval constructs an interval of numbers which will contain the true parameter of the population (e.g.¬†the mean) in \\((1-\\alpha)\\) times of cases. \\(\\alpha\\) is usually chosen to be small, so that our confidence interval has a probability of 95% or 99% confidence level The confidence level is the probability with which the confidence interval is believed to contain the true parameter of the population and is defined as \\((1-\\alpha)\\) correlation The statistical dependence of two random variables which is determined by pairwise comparison of values covariance A measure which assesses the degree to which the values of two variables (\\(X_i\\) and \\(X_j\\)) vary together (their joint variability). degrees of freedom Degrees of freedom express constraints on our estimation process by specifying how many values in the calculation are free to vary dichotomous Can only assume two mutually exclusive, but internally homogeneous qualitative categories dummy variable Dummy variables are dichotomous, categorical variables which indicate the presence or the absence of a characteristic. error term The error term quantifies the distance between each observation and the corresponding point on the regression line. The terms are denoted as \\(\\epsilon_{i}\\) heteroscedasticity The variability of the error terms changes for different observations \\(X\\) homoscedasticity Refers to a constant variance of the error terms intercept The intercept is the point at which the regression line intersects the y-axis. In this book we denote it as \\(\\beta_{0}\\) law of iterative expectations According to this law, ‚Äúthe expected value of X is equal to the expectationover the conditional expectation of X given Y‚Äù (Robinson, 2022) logarithm Logarithm is defined as the exponent or power to which a base must be raised to yield a given number. Expressed mathematically, \\(x\\) is the logarithm of \\(n\\) to the base \\(b\\) if \\(b^x = n\\), in which case \\(x = log_b n\\) (Murray, 2023) matrix A ‚Äúset of numbers arranged in rows and columns so as to form a rectangular array‚Äù (Ronan, 2023) model building Running a number of regression models, each testing a different combination of variables. multicollinearity A situation in which an independent variable is a function of multiple other independent variables in the regression model omitted variable bias If you omit an important variable in a regression model, it will bias the size of other coefficients if the variables are correlated. Ordinary Least Squares The method of fitting a regression line by means of minimizing the sum of the squared distances between the observations and the estimated values outer product The outer product of two vectors results in a matrix in which each element is the product of corresponding elements from the first vector (rows) and the second vector (columns). parsimony Refers to the principle . partial slope coefficient A partial slope coefficient measures the influence of a variable in multiple regression, holding all other independent variables in the model constant Population Regression Function The Population Regression Function (PRF) describes the expected distribution of \\(y\\), given the values of the independent variable(s) \\(x\\). It is also called the conditional expectation function (CEF) and can be denoted as \\(E(y_{i}|x_{i})\\) reference category The category of a dummy variable in respect to which the effect on the value of the dependent variable is displayed regression Regression analysis determines the direction and magnitude of influence of one or more independent variables on a dependent variable regression line The regression line describes how the dependent variable is functionally related to the values of the independent variable. It it defined by the intercept \\(\\beta_{0}\\) and the slope \\(\\beta_{1}\\) residual An estimation of the error term. The difference between an observation \\(y_{i}\\) and the estimated value \\(\\hat{y}_{i}\\). Denoted as \\(\\hat{\\epsilon}_{i}\\) robust standard errors Also known as Huber-White standard errors, correct for heteroscedasticity by ‚Äú[adjusting] the model-based standard errors using the empirical variability of the model residuals‚Äù (Mansournia et al., 2020, p. 347) Sample Regression Function A regression line based on a randomly drawn sample significance level Is denoted as \\(\\alpha\\) and defined as \\(1-\\)confidence level. slope A slope is defined as rise over run, and so it tells us how many units of y we need to climb (or descend if the slope is negative) for every additional unit of the independent variable \\(x\\) time-series data Time-series data review a certain characteristic over time \\(t\\), where \\(t\\) runs from 1 to \\(T\\) Variance-Covariance Matrix A variance-covariance matrix is a square matrix that encapsulates the variances of different variables on its diagonal and the covariances between pairs of variables in its off-diagonal elements.¬† Variance Inflation Factor (VIF) A measure to quantify the how much larger the observed variance of a coefficient is compared to a scenario in which the variable was totally functionally independent from the other independent variables in the model "],["list-of-references.html", "List of References", " List of References Agresti, A. (2018). Statistical Methods for the Social Sciences (Fifth). Harlow: Pearson. Arel-Bundock, V. (2022). modelsummary: Data and Model Summaries in R. Journal of Statistical Software, 103(1), 1‚Äì23. Boix, C., Miller, M., &amp; Rosato, S. (2018). Boix-Miller-Rosato Dichotomous Coding of Democracy, 1800-2015 (Version V3). Harvard Dataverse. GOV.UK. (2013). National Statistics: Income and tax by Parliamentary constituency. available online at https://www.gov.uk/government/statistics/income-and-tax-by-parliamentary-constituency-2010-to-2011. Gujarati, D. N., &amp; Porter, D. C. (2009). Basic Econometrics (Fifth International Edition). New York: McGraw-Hill. House of Commons Library. (n.d.). Data Dashboard. available online at https://commonslibrary.parliament.uk/type/data-dashboard/. London Data Store. (2010). London Parliamentary Constituency Profiles 2010. available online at https://data.london.gov.uk/dataset/london-parliamentary-constituency-profiles. London Data Store. (2013). Ward Profiles and Atlas. available online at https://data.london.gov.uk/dataset/ward-profiles-and-atlas. Mansournia, M. A., Nazemipour, M., Naimi, A. I., Collins, G. S., &amp; Campbell, M. J. (2020). Reflection on modern methods: demystifying robust standard errors for epidemiologists. International Journal of Epidemiology, 50(1), 346‚Äì351. https://doi.org/10.1093/ije/dyaa260 Marshall, M. G., &amp; Gurr, T. R. (2020). Polity V Project: Political Regime Characteristics and Transitions, 1800-2018. available online at http://www.systemicpeace.org/inscrdata.html. Murray, F. J. (2023). logarithm. In Encyclopedia Britannica. available online at https://www.britannica.com/science/logarithm. Reiche, F. (forthcoming). Introduction to Quantitative Methods in the Social Sciences. Oxford: Oxford University Press. Robinson, T. S. (2022). 10 Fundamental Theorems for Econometrics. available online at https://bookdown.org/ts_robinson1994/10_fundamental_theorems_for_econometrics/exp-theorems.html. Ronan, M. A. (2023). matrix. In Encyclopedia Britannica. available online at https://www.britannica.com/science/matrix-mathematics. University of Manchester, Cathie Marsh Institute for Social Research (CMIST), UK Data Service, Office for National Statistics. (2019). Crime Survey for England and Wales, 2013-2014: Unrestricted Access Teaching Dataset. available online at https://doi.org/10.5255/UKDA-SN-8011-1. World Bank. (2024). World Development Indicators, 21.02.2024. available online at https://datacatalog.worldbank.org/dataset/world-development-indicators. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
